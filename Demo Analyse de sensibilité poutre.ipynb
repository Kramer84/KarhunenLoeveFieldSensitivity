{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il est explicité ici l'utilisation des ensembles de codes écrits pour l'analyse de sensibilité sur des champs stochastiques et variables aléatoires.\n",
    "\n",
    "### Il est d'abord conseillé d'installer l'environnement virtuel dont la définition se trouvent dans le fichier yaml\n",
    "\n",
    "Nous allons faire ici l'analyse de sensiblité sur une poutre en flexion représentée par 100 éléments finis, et ou le module young et le diamètre de chaque élément est déterminé par un processus gaussien en une dimension. La position de la force, sa norme, tout comme la densité du matérieau sont déterminés par des lois nomales gaussiennes.\n",
    "Dans la logique d'écriture de ces codes, il faut avoir un à priori sur les processus gaussiens, la loi qu'ils suivent, tout comme sur les paramètres des lois gaussiennes. Ensuite, il faut avoir une fonction python qui prend en entrée ces champs, et qui renvoie un ensemble connu de resultas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import anastruct, openturns, numba, joblib\n",
    "except:\n",
    "    import os\n",
    "    if os.sys.platform == 'linux' :\n",
    "        file_path = 'sensitivityEnv.yml'\n",
    "        os.system('conda env create -f'+file_path)\n",
    "        # to have the right modules installed\n",
    "        print('now activate the environment and restart jupyter with other kernel')\n",
    "    else :\n",
    "        print('Do it alone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend function args:  ['x']  trend function:  210000 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n",
      "trend function args:  ['x']  trend function:  10 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n"
     ]
    }
   ],
   "source": [
    "# Voici les deux scripts destinés à gérer l'analyse de sensibilité sur les champs stochastiques\n",
    "import NdGaussianProcessSensitivity as ngps\n",
    "import NdGaussianProcessConstructor as ngpc\n",
    "# Classes utilitaires\n",
    "import numpy as np\n",
    "import openturns as ot\n",
    "# on importe aussi les fonctions à étudier\n",
    "import RandomBeamGenerationClass    as rbgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord, nous définisson l'ensemble de nos variables d'entrée, tout comme les variables de sortie :\n",
    "- L'on va définir un par un tout les processus et variables aléatoires utilisées dans notre model. Bien sûr cela implique d'avoir un à-priori sur le comportement de ces différentes lois probabilistes. \n",
    "- Néanmoins, comme nous en sommes à des codes d'essai, il serait assez trivial de rajouter la prossiblité de récuperer l'approximation d'un champ inconnu avec l'approcimation de Karhunen - Loeve, en présence d'un grand nombre de mesures.\n",
    "- La définition des éléments sur lesquels est construit le champ stochastique est un peu différent de la manière interne à openturns. En effet, s'étant placés directement dans un cadre de poutre en 'éléments finis, ou l'on a N+1 noeuds (N étant le nombre de poutres), il faut savoir si N est le nombre de mailles ou le nombre de noeuds. Dans le choix a été fait ici de définir la taille du maillage (grid_shape) de la manière suivante :\n",
    "> grid_shape = [[position_X0, longeur_totaleX, nombre_mailles], [position_Y0, longeur_totaleY, nombre_mailles], ..]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend function args:  ['x']  trend function:  210000 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n",
      "trend function args:  ['x']  trend function:  10 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n"
     ]
    }
   ],
   "source": [
    "# process governing the young modulus for each element      (MPa)\n",
    "process_E = ngpc.NdGaussianProcessConstructor(dimension=1,\n",
    "                                              grid_shape=[[0,1000,100],],\n",
    "                                              covariance_model={'NameModel':'MaternModel',\n",
    "                                                                'amplitude':5000.,\n",
    "                                                                'scale':300,\n",
    "                                                                'nu':13/3},\n",
    "                                              trend_arguments=['x'],trend_function=210000)\n",
    "process_E.setName('E_')\n",
    "\n",
    "# process governing the diameter for each element          (mm)\n",
    "process_D = ngpc.NdGaussianProcessConstructor(dimension=1,\n",
    "                                              grid_shape=[[0,1000,100],],\n",
    "                                              covariance_model={'NameModel':'MaternModel',\n",
    "                                                                'amplitude':.3,\n",
    "                                                                'scale':250,\n",
    "                                                                'nu':7.4/3},\n",
    "                                              trend_arguments=['x'],trend_function=10)\n",
    "process_D.setName('D_')\n",
    "\n",
    "# random variable for the density of the material (kg/m³)\n",
    "rho         = 7850.\n",
    "sigma       = 250\n",
    "nameD       = 'Rho'\n",
    "RV_Rho = ngpc.NormalDistribution(mu = rho, sigma = sigma, name = nameD)\n",
    "\n",
    "# random variable for the position of the force   (mm) \n",
    "middle       = 500\n",
    "sigma_f      = 50\n",
    "namePos     = 'FP'\n",
    "RV_Fpos = ngpc.NormalDistribution(mu = middle, sigma = sigma_f, name = namePos)\n",
    "\n",
    "# random variable for the norm of the force    (N)\n",
    "muForce       = 100\n",
    "sigma_Fnor    = 15\n",
    "nameNor       = 'FN'\n",
    "RV_Fnorm = ngpc.NormalDistribution(mu = muForce, sigma = sigma_Fnor, name = nameNor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de noter que les processus et variables aléatoires doivent être définies à partir du module \n",
    "NdGaussianProcessConstructor, qui contient les classes suivantes : \n",
    "###### Classe pour construire un champ stochastique : \n",
    "> NdGaussianProcessConstructor.NdGaussianProcessConstructor() \n",
    "###### Classe pour construire une variables aléatoire  : \n",
    "> NdGaussianProcessConstructor.NormalDistribution() ## Classe openturns.Normal() suchargée\n",
    "###### Classe pour construire un vecteur de variables aléatoires normales : \n",
    "> NdGaussianProcessConstructor.RandomNormalVector() ## Classe openturns.PythonRandomVector surchargée. Cette dernière est utilisée en interne par NdGaussianProcessConstructor.\n",
    "\n",
    "**Finalement, l'autre particularité du NdGaussianProcessConstructor, est d'utiliser un objet _numpy.memmap_ modifiée, qui enregistre les échantillons de processus gaussiens sous forme de fichier temporaire dans le directoire d'utilisation des codes et les éfface en sortant du code**\n",
    "\n",
    "L'on définit ensuite les variables de sortie. Il faut connaître l'ordre dans lequel la fonction renvoie ses resultats connaitre leur nom comme leur dimension. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(ngps)\n",
    "outputVariables = {'out1' :\n",
    "                   {\n",
    "                         'name'     : 'VonMisesStress',\n",
    "                         'position' : 0,\n",
    "                         'shape'    : (102,)  \n",
    "                    },\n",
    "                   'out2' :\n",
    "                   {\n",
    "                        'name'      : 'maxDeflection',\n",
    "                        'position'  : 1,\n",
    "                        'shape'     : (1,)\n",
    "                   }\n",
    "                  }\n",
    "#Pour utiliser notre fonction, un wrapper a été spécialement écrit pour faciliter l'accès aux fonctions mais\n",
    "#ce choix est entièrement dépendant de la manière ont a été définie la fonction sur laquelle vous travaillez.\n",
    "functionWrapper = rbgc.sampleAndSoloFunctionWrapper(process_E, process_D, RV_Rho, RV_Fpos, RV_Fnorm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite, on crée une instance pour l'analyse de sensibilité.\n",
    "Il faut donner en entrée une liste contenant les procéssus et les variables aléatoires **dans l'ordre** dans lequel la fonction les recoit. \n",
    "\n",
    "*Pour cela il faut aussi connaître l'ordre des variables d'entrée de la fonction et leur nombre.*\n",
    "\n",
    "**Ces fonctions sont celles qui prennent entrée des champs aléatoires (vecteurs et matrices, de type *list ou numpy*) et variables aléatoire (scalaires (vecteurs 1D pour le multiprocessing)) et non pas les fonctions prennant en entrée les variables aléatoires issues de la décomposition de la Karhunen Loeve, qui elles sont construites en interne dans la classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend function args:  ['x']  trend function:  210000 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n",
      "trend function args:  ['x']  trend function:  10 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n"
     ]
    }
   ],
   "source": [
    "inputVarList = [process_E, process_D, RV_Rho, RV_Fpos, RV_Fnorm]\n",
    "# We also the need the two functions of the model (one for samples, the other for single evaluations)\n",
    "# In our case, as our model is defined as a class, we have to first create the model, \n",
    "# but it also could just be just two functions taking as an input the fields and RVs\n",
    "soloFunction   = functionWrapper.randomBeamFunctionSolo\n",
    "sampleFunction = functionWrapper.randomBeamFunctionSample\n",
    "##\n",
    "size           = 40 ## Number of samples for our sobol indicies experiment (kept low here to make things faster)\n",
    "##\n",
    "processSensitivityAnalysis = ngps.NdGaussianProcessSensitivityAnalysis(inputVarList, \n",
    "                                                                       outputVariables,\n",
    "                                                                       sampleFunction,\n",
    "                                                                       soloFunction,\n",
    "                                                                       size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une vue du dictionnaire intermédiaire qui est crée une fois les processus et variables aléatoires d'entrées définies :\n",
    "\n",
    "On voit que la position des processus dans les arguments de la fonction d'entrée est enregistrée dans le dictionnaire dans la clé *position* et viennent de la manière de laquelle on a mis les VA et Processus dans le vecteur inputVarList. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite, grace à l'intermédiaire de la classe ot.SobolIndiciesExperiment, on génère les' variables aléatoires d'entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(inputDesign) =  1040\n",
      "input design is:         [ E_xi_0      E_xi_1      E_xi_2      ... Rho         FP          FN          ]\n",
      "   0 : [   53.648      -1.98668    23.2094   ... 7877.33      487.673      88.2397   ]\n",
      "   1 : [   55.7515     -0.912282   24.5215   ... 7997.63      435.915      77.6556   ]\n",
      "   2 : [   55.0882      1.52042    24.7405   ... 8315.24      516.28      111.366    ]\n",
      "...\n",
      "1037 : [   51.3822      0.531884   25.2578   ... 7680.89      446.732     104.417    ]\n",
      "1038 : [   55.872      -0.855109   24.9704   ... 7934.92      440.321      82.5617   ]\n",
      "1039 : [   56.1749      0.892544   22.772    ... 8299.26      468.711     105.885    ]\n"
     ]
    }
   ],
   "source": [
    "processSensitivityAnalysis.prepareSobolIndicesExperiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend function args:  ['x']  trend function:  210000 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n",
      "trend function args:  ['x']  trend function:  10 \n",
      "\n",
      "Please be aware that the number of elements in the argument list has to be the same as the dimension of the process:  1\n"
     ]
    }
   ],
   "source": [
    "reload(ngps)\n",
    "inputDes = np.load('inputDesign.npy',allow_pickle=True)\n",
    "inputDesNc = np.load('inputDesignNc.npy',allow_pickle=True)\n",
    "processSensitivityAnalysis = ngps.NdGaussianProcessSensitivityAnalysis(inputVarList, \n",
    "                                                                       outputVariables,\n",
    "                                                                       sampleFunction,\n",
    "                                                                       soloFunction,\n",
    "                                                                       size)\n",
    "processSensitivityAnalysis.inputDesign = inputDes\n",
    "processSensitivityAnalysis._inputDesignNC = inputDesNc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite on récupère les sorties associées aux entrées génerées. \n",
    "L'idée du postprocessing est d'identifier si dans les sorties il y a des valeurs de type np.nan, et de refaire les experiences manquantes tant qu'il y a des np.nan de présents.\n",
    "\n",
    "**Ceci crée quelques problèmes : En effet, si le calcul numérique n'a pas pu aboutir avec une certaine réalisation des variables en entrée, est-ce que cela veut dire que cette réalisation est défaillante? Va-t-on l'inclure dans le cas du calcul de la défaillance ou de la sensibilité? Car si on l'inclut pas, il se peut qu'on oublie un nombre conséquent de modes défaillants. Solution : changer le modèle informatique et le rendre robuste à ces erreurs, ou faire une étude précise avec ces réalisation particulières.**\n",
    "\n",
    "\n",
    "La solution retenue pour génerer les experiences manquantes est d'itérer au dessus de chaque index de la sortie ou se trouvent les nans, de refaire une experience de sobol de taille 1 ( donc qui renverra d+2 valeurs, avec d la dimension de l'entrée), de générer les sorties correspondant aux entrées (recommencer si il s'y trouve un np.nan), et de remplacer les d+2 valeurs du inputDesign d'entrée avec celles que l'on vient de regénérer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (1040, 103)  should be [N,10X] something\n",
      "maxDeflection list:  [22.17614215 16.80989185 21.93583895 17.41561363 22.50603087 17.95891894\n",
      " 18.73175937 23.28153639 26.45604793 22.76542661 19.65620801 25.0052461\n",
      " 29.64726163 20.36505131 19.36147347 17.6870062  16.26091805 19.65929871\n",
      " 13.06834139 20.89955123 17.16247955 21.05945664 22.91020409 22.52660179\n",
      " 18.57490994 20.00832017 18.25249565 20.87327908 21.16395579 22.51000968\n",
      " 15.45092384 19.07723803 22.49262591 18.1702287  16.70941053 15.60378439\n",
      " 21.28061765 19.58798781 19.91709646 15.27863935 16.52542267 20.36816389]\n",
      "deflection std deviation  nan\n",
      "timed  96.689670086  s for function \" randomBeamFunctionSample \"\n",
      "Converting list of outputs into matrix: \n",
      "Element  1  has shape  (1040, 102)\n",
      "Element  2  has shape  (1040,)\n",
      "Final shape matrix:  (1040, 103)\n",
      "columns where nan :  [42]\n",
      "There were  1  errors (numpy.nan) while processing, trying to regenerate missing outputs \n",
      "\n",
      "index to change:  [   2   42   82  122  162  202  242  282  322  362  402  442  482  522\n",
      "  562  602  642  682  722  762  802  842  882  922  962 1002]\n",
      "shape deflection:  (26, 103)  should be [N,10X] something\n",
      "maxDeflection list:  [22.30349329 14.89234535 22.25069117 22.30480958 21.95927862 22.31505144\n",
      " 22.33711073 22.30118691 22.30223727 22.30349329 20.16611138 22.22722449\n",
      " 22.84395101 22.18388329 22.5112945  22.27769064 22.31263157 22.29050226\n",
      " 22.30016102 22.3013744  22.30303627 22.3018094  22.30353673 22.30349329\n",
      " 22.7589692  15.77646134]\n",
      "deflection std deviation  1.8972696840457417\n",
      "timed  2.030698776  s for function \" randomBeamFunctionSample \"\n",
      "Converting list of outputs into matrix: \n",
      "Element  1  has shape  (26, 102)\n",
      "Element  2  has shape  (26,)\n",
      "Final shape matrix:  (26, 103)\n",
      "new input design length:  26\n",
      "new output design shape:  (26, 103)\n",
      " - Correction assertion passed - \n",
      "\n",
      "Transforming matrix of shape  (1040, 103)\n",
      "Into list of Ndarrays according to output definition\n",
      "Dimension output  0  is  102\n",
      "Intermediary shape is : (1040, 102)\n",
      "new shape is:  [1040, 102]\n",
      "Output element  0  has shape  (1040, 102)\n",
      "Dimension output  1  is  1\n",
      "Intermediary shape is : (1040, 1)\n",
      "new shape is:  [1040, 1]\n",
      "Output element  1  has shape  (1040,)\n"
     ]
    }
   ],
   "source": [
    "processSensitivityAnalysis.getOutputDesignAndPostprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le *timing* vient de la classe ***custum_wraps***, qui est pour l'instant assez inutile, mais permet de prendre en main les décorateurs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<TABLE><TR><TH></TH><TH>E_xi_0</TH><TH>E_xi_1</TH><TH>E_xi_2</TH><TH COLSPAN=\"18\">...</TH><TH>Rho</TH><TH>FP</TH><TH>FN</TH></TR>\n",
       "<TR><TD>0</TD><TD>54.5451289795226</TD><TD>0.05000833903005401</TD><TD>23.137307294955463<TD COLSPAN=\"18\">...</TD><TD>7891.8932199872625</TD><TD>461.4721009365869</TD><TD>104.37479189386171</TD></TR>\n",
       "<TR><TD>1</TD><TD>53.92282369321113</TD><TD>1.8660882698007146</TD><TD>23.27429190723908<TD COLSPAN=\"18\">...</TD><TD>7728.337388066729</TD><TD>588.6938515695771</TD><TD>91.99906909323967</TD></TR>\n",
       "<TR><TD>2</TD><TD>54.20086085919717</TD><TD>-0.3769834740060741</TD><TD>24.901588341624095<TD COLSPAN=\"18\">...</TD><TD>7728.595828546258</TD><TD>439.61197873858976</TD><TD>111.61214894125376</TD></TR>\n",
       "<TR><TD COLSPAN=\"25\">...</TD></TR>\n",
       "<TR><TD>1037</TD><TD>54.24162033380902</TD><TD>-0.16318208371962473</TD><TD>22.67614608447978<TD COLSPAN=\"18\">...</TD><TD>7897.956309241204</TD><TD>557.7128756203122</TD><TD>107.78257399879804</TD></TR>\n",
       "<TR><TD>1038</TD><TD>54.08515342852437</TD><TD>-3.2580209093194235</TD><TD>24.07180972113459<TD COLSPAN=\"18\">...</TD><TD>8126.08930551776</TD><TD>527.6695630196714</TD><TD>123.66256234508408</TD></TR>\n",
       "<TR><TD>1039</TD><TD>55.03247209956342</TD><TD>-1.9977965642480404</TD><TD>25.668617968897014<TD COLSPAN=\"18\">...</TD><TD>8382.753548034743</TD><TD>531.3403608227076</TD><TD>75.24020254109175</TD></TR>\n",
       "</TABLE>"
      ],
      "text/plain": [
       "class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=1040 dimension=24 description=[E_xi_0,E_xi_1,E_xi_2,...,Rho,FP,FN] data=[[54.5451,0.0500083,23.1373,...,7891.89,461.472,104.375],[53.9228,1.86609,23.2743,...,7728.34,588.694,91.9991],[54.2009,-0.376983,24.9016,...,7728.6,439.612,111.612],...,[54.2416,-0.163182,22.6761,...,7897.96,557.713,107.783],[54.0852,-3.25802,24.0718,...,8126.09,527.67,123.663],[55.0325,-1.9978,25.6686,...,8382.75,531.34,75.2402]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(processSensitivityAnalysis.outputDesignList)) ## to be sure\n",
    "output = processSensitivityAnalysis.outputDesignList ## We take the corrected output design\n",
    "processSensitivityAnalysis.inputDesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       [ E_xi_0       E_xi_1       E_xi_2       ... Rho          FP           FN           ]\n",
      "   0 : [   54.5451       0.0500083   23.1373    ... 7891.89       461.472      104.375     ]\n",
      "   1 : [   53.9228       1.86609     23.2743    ... 7728.34       588.694       91.9991    ]\n",
      "   2 : [   54.2009      -0.376983    24.9016    ... 7728.6        439.612      111.612     ]\n",
      "...\n",
      "1037 : [   54.2416      -0.163182    22.6761    ... 7897.96       557.713      107.783     ]\n",
      "1038 : [   54.0852      -3.25802     24.0718    ... 8126.09       527.67       123.663     ]\n",
      "1039 : [   55.0325      -1.9978      25.6686    ... 8382.75       531.34        75.2402    ]\n",
      "3.8257519378494487\n",
      "1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8257519378494487"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = processSensitivityAnalysis._outputDesignListNC\n",
    "print(processSensitivityAnalysis.inputDesign)\n",
    "print(processSensitivityAnalysis.outputDesignList[1][42,...])\n",
    "uu=ot.SaltelliSensitivityAlgorithm(inputDes,np.expand_dims(output[1], 1), size)\n",
    "print(len(inputDes))\n",
    "inputArr = np.array(inputDes)\n",
    "np.argwhere(np.isnan(output[1]))\n",
    "output[1][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape is:  102\n",
      "sobol field shape:  [1, 102]\n",
      "Shape sensitivity field :  (1, 102)\n",
      "new shape is:  1\n",
      "[5.32174173 5.80617237 5.27570373 ... 6.15864666 7.09829272 3.70079264]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>[-0.0965959,-0.0966484,-0.0965763,-0.0966216,-0.0966157,-0.0966263,-0.0966127,-0.0966767,-0.0626493,0.0437696,-0.0494265,-0.0910594,-0.133882,-0.0752132,-0.0830312,-0.0982919,-0.0968424,-0.0930179,-0.0936057,-0.0967187,-0.0977158,-0.0966767,0.280053,0.782144]#24</p>"
      ],
      "text/plain": [
       "class=Point name=Unnamed dimension=24 values=[-0.0965959,-0.0966484,-0.0965763,-0.0966216,-0.0966157,-0.0966263,-0.0966127,-0.0966767,-0.0626493,0.0437696,-0.0494265,-0.0910594,-0.133882,-0.0752132,-0.0830312,-0.0982919,-0.0968424,-0.0930179,-0.0936057,-0.0967187,-0.0977158,-0.0966767,0.280053,0.782144]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = processSensitivityAnalysis.getSobolIndiciesKLCoefs()\n",
    "import matplotlib.pyplot as plt\n",
    "test[0][0,2].getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "[  1.74255148   6.17303613  11.8903633   17.67049123  23.49888823\n",
      "  29.38239247  35.31138731  41.25849752  47.1847756   53.048955\n",
      "  58.8174411   64.47281592  70.01929805  75.48413992  80.91513412\n",
      "  86.37499059  91.93376928  97.66056056 103.61551779 109.84280963\n",
      " 116.36520093 123.18065661 130.26159376 137.55701273 144.99773848\n",
      " 152.5045597  159.99821791 167.40988188 174.69051824 181.81714062\n",
      " 188.79521826 195.65673697 202.45423997 209.25233836 216.11796977\n",
      " 223.11067274 230.27444668 237.63191962 245.18119061 252.89609094\n",
      " 260.72920856 268.61777104 276.49143768 284.28074331 291.92528363\n",
      " 297.43900688 297.36119331 292.61143035 287.61497793 282.40808202\n",
      " 277.03353032 271.53371535 265.94501212 260.29436591 254.59808488\n",
      " 248.86299341 243.08917305 237.27407301 231.41649613 225.52013171\n",
      " 219.59580689 213.66189637 207.74330229 201.86861431 196.06645136\n",
      " 190.3614563  184.77069072 179.30082675 173.94702394 168.69306007\n",
      " 163.5131772  158.3752344  153.24482968 148.08965317 142.88390229\n",
      " 137.61148101 132.26791215 126.8604817  121.40644013 115.93003655\n",
      " 110.45833185 105.01697843  99.62649185  94.2996543   89.04022503\n",
      "  83.84352704  78.69816952  73.58903373  68.50087079  63.42174802\n",
      "  58.34613661  53.2764321   48.22293506  43.20198226  38.23251978\n",
      "  33.33150357  28.50933913  23.76558053  19.08607771  14.44227534\n",
      "   9.79550321   5.12935014]\n",
      "[  1.74255148   6.17303613  11.8903633   17.67049123  23.49888823\n",
      "  29.38239247  35.31138731  41.25849752  47.1847756   53.048955\n",
      "  58.8174411   64.47281592  70.01929805  75.48413992  80.91513412\n",
      "  86.37499059  91.93376928  97.66056056 103.61551779 109.84280963\n",
      " 116.36520093 123.18065661 130.26159376 137.55701273 144.99773848\n",
      " 152.5045597  159.99821791 167.40988188 174.69051824 181.81714062\n",
      " 188.79521826 195.65673697 202.45423997 209.25233836 216.11796977\n",
      " 223.11067274 230.27444668 237.63191962 245.18119061 252.89609094\n",
      " 260.72920856 268.61777104 276.49143768 284.28074331 291.92528363\n",
      " 297.43900688 297.36119331 292.61143035 287.61497793 282.40808202\n",
      " 277.03353032 271.53371535 265.94501212 260.29436591 254.59808488\n",
      " 248.86299341 243.08917305 237.27407301 231.41649613 225.52013171\n",
      " 219.59580689 213.66189637 207.74330229 201.86861431 196.06645136\n",
      " 190.3614563  184.77069072 179.30082675 173.94702394 168.69306007\n",
      " 163.5131772  158.3752344  153.24482968 148.08965317 142.88390229\n",
      " 137.61148101 132.26791215 126.8604817  121.40644013 115.93003655\n",
      " 110.45833185 105.01697843  99.62649185  94.2996543   89.04022503\n",
      "  83.84352704  78.69816952  73.58903373  68.50087079  63.42174802\n",
      "  58.34613661  53.2764321   48.22293506  43.20198226  38.23251978\n",
      "  33.33150357  28.50933913  23.76558053  19.08607771  14.44227534\n",
      "   9.79550321   5.12935014]\n"
     ]
    }
   ],
   "source": [
    "inputArray = np.array(processSensitivityAnalysis.inputDesign)\n",
    "inputArrayNc = np.array(processSensitivityAnalysis._inputDesignNC)\n",
    "outputArray = processSensitivityAnalysis.outputDesignList[0]\n",
    "outputArrayNc = processSensitivityAnalysis._outputDesignListNC[0]\n",
    "print(np.array_equal(inputArray, inputArrayNc))\n",
    "print(np.array_equal(outputArray, outputArrayNc))\n",
    "print(outputArray[43])\n",
    "print(outputArrayNc[43])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1040,102) into shape (1040)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-54a9b9ac3912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessSensitivityAnalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputDesign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1040,102) into shape (1040)"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(np.isnan(output)))\n",
    "print(min(outputList[0]))\n",
    "print(max(outputList[0]))\n",
    "print(processSensitivityAnalysis.inputDesign)\n",
    "print(np.expand_dims(output[...,50], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-4ee24acdb71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputDesign\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprocessSensitivityAnalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputDesign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputList\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDesign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msensitivityAnalysisList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaltelliSensitivityAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDesign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "inputDesign  = processSensitivityAnalysis.inputDesign\n",
    "inputList    = np.asarray(inputDesign).tolist()\n",
    "print(len(inputList))\n",
    "print(len(outputList[10]))\n",
    "sensitivityAnalysisList = [ot.SaltelliSensitivityAlgorithm(inputDesign, np.expand_dims(output[...,i], 1), size) for i in range(len(outputList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysisList[0].getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sobolIndiciesList = [sensitivityAnalysisList[i].getFirstOrderIndices() for i in range(len(sensitivityAnalysisList))]\n",
    "sobolIndiciesArr  = np.asarray(sobolIndiciesList)\n",
    "print(sobolIndiciesArr.shape)\n",
    "plt.imshow(sobolIndiciesArr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(inputDesign.add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDesign[0] = np.arange(24).tolist()\n",
    "inputDesign[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputVariables.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=functionWrapper.results[1]\n",
    "print(x.shape)\n",
    "x1 = x[:,1,:]\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
