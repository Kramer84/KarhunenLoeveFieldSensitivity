{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il est explicité ici l'utilisation des ensembles de codes écrits pour l'analyse de sensibilité sur des champs stochastiques et variables aléatoires.\n",
    "\n",
    "### Il est d'abord conseillé d'installer l'environnement virtuel dont la définition se trouvent dans le fichier yaml\n",
    "\n",
    "Nous allons faire ici l'analyse de sensiblité sur une poutre en flexion représentée par 100 éléments finis, et ou le module young et le diamètre de chaque élément est déterminé par un processus gaussien en une dimension. La position de la force, sa norme, tout comme la densité du matérieau sont déterminés par des lois nomales gaussiennes.\n",
    "Dans la logique d'écriture de ces codes, il faut avoir un à priori sur les processus gaussiens, la loi qu'ils suivent, tout comme sur les paramètres des lois gaussiennes. Ensuite, il faut avoir une fonction python qui prend en entrée ces champs, et qui renvoie un ensemble connu de resultas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Essai pour voir si les packages nécessaires sont installés\n",
    "try:\n",
    "    import anastruct, openturns, numba, joblib\n",
    "except:\n",
    "    import os\n",
    "    if os.sys.platform == 'linux' :\n",
    "        file_path = 'sensitivityEnv.yml'\n",
    "        os.system('conda env create -f'+file_path)\n",
    "        # to have the right modules installed\n",
    "        print('now activate the environment and restart jupyter with other kernel')\n",
    "    else :\n",
    "        print('Do it alone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len vertices is: 101\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "# Voici les deux scripts destinés à gérer l'analyse de sensibilité sur les champs stochastiques\n",
    "import spsa as spsa\n",
    "# Classes utilitaires\n",
    "import numpy                        as np\n",
    "import openturns                    as ot\n",
    "import matplotlib.pyplot            as plt\n",
    "from   importlib                import reload \n",
    "# on importe aussi les fonctions à étudier\n",
    "import beamExample as PBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord, nous définisson l'ensemble de nos variables d'entrée, tout comme les variables de sortie :\n",
    "- L'on va définir un par un tout les processus et variables aléatoires utilisées dans notre model. Bien sûr cela implique d'avoir un à-priori sur le comportement de ces différentes lois probabilistes. \n",
    "- Néanmoins, comme nous en sommes à des codes d'essai, il serait assez trivial de rajouter la prossiblité de récuperer l'approximation d'un champ inconnu avec l'approcimation de Karhunen - Loeve, en présence d'un grand nombre de mesures.\n",
    "- La définition des éléments sur lesquels est construit le champ stochastique est un peu différent de la manière interne à openturns. En effet, s'étant placés directement dans un cadre de poutre en 'éléments finis, ou l'on a N+1 noeuds (N étant le nombre de poutres), il faut savoir si N est le nombre de mailles ou le nombre de noeuds. Dans le choix a été fait ici de définir la taille du maillage (grid_shape) de la manière suivante :\n",
    "> grid_shape = [[position_X0, longeur_totaleX, nombre_mailles], [position_Y0, longeur_totaleY, nombre_mailles], ..]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process governing the young modulus for each element (MPa)\n",
    "process_E = spsa.StochasticProcessConstructor(dimension=1,\n",
    "                                        grid_shape=[[0,1000,99],],\n",
    "                                        covariance_model={'Model':'MaternModel',\n",
    "                                                        'amplitude':[50000],\n",
    "                                                        'scale':[300],\n",
    "                                                        'nu':13/3},\n",
    "                                        trend_arguments=['x'],trend_function=210000)\n",
    "process_E.setName('E_')\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "# process governing the diameter for each element (mm) \n",
    "# other constructor shown \n",
    "process_D = spsa.StochasticProcessConstructor()\n",
    "process_D.setDimension(1)\n",
    "process_D.setGrid([[0,1000,99],])\n",
    "#setCovarianceModel also accepts any of the models defined in openturns, already initialised\n",
    "#with the right parameters, not only dictionaries\n",
    "process_D.setCovarianceModel(covarianceModelDict = {'Model':'MaternModel',\n",
    "                                                    'amplitude':[.3],\n",
    "                                                    'scale':[250],\n",
    "                                                    'nu':7.4/3})\n",
    "process_D.setTrend(['X'], 10)\n",
    "process_D.setName('D_')\n",
    "\n",
    "###########################################################################################################\n",
    "# random variable for the position of the force   (mm) \n",
    "middle       = 500\n",
    "sigma_f      = 50\n",
    "namePos     = 'FP'\n",
    "RV_Fpos = ot.Normal(middle, sigma_f)\n",
    "RV_Fpos.setName(namePos)\n",
    "\n",
    "###########################################################################################################\n",
    "# random variable for the norm of the force    (N)\n",
    "muForce       = 100\n",
    "# we go from sigma = 15 to sigma = 1.5, as the influence is too important\n",
    "sigma_Fnor    = 5.5\n",
    "nameNor       = 'FN'\n",
    "RV_Fnorm  = ot.Normal(muForce, sigma_Fnor)\n",
    "RV_Fnorm.setName(nameNor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<TABLE><TR><TD></TD><TH>v0</TH><TH>y0</TH></TR>\n",
       "<TR><TH>0</TH><TD>0</TD><TD>177479.1</TD></TR>\n",
       "<TR><TH>1</TH><TD>10.10101</TD><TD>176009.1</TD></TR>\n",
       "<TR><TH>2</TH><TD>20.20202</TD><TD>174582.4</TD></TR>\n",
       "<TR><TH>3</TH><TD>30.30303</TD><TD>173203.2</TD></TR>\n",
       "<TR><TH>4</TH><TD>40.40404</TD><TD>171870.2</TD></TR>\n",
       "<TR><TH>5</TH><TD>50.50505</TD><TD>170581.4</TD></TR>\n",
       "<TR><TH>6</TH><TD>60.60606</TD><TD>169334.3</TD></TR>\n",
       "<TR><TH>7</TH><TD>70.70707</TD><TD>168125.9</TD></TR>\n",
       "<TR><TH>8</TH><TD>80.80808</TD><TD>166957.7</TD></TR>\n",
       "<TR><TH>9</TH><TD>90.90909</TD><TD>165833.2</TD></TR>\n",
       "<TR><TH>10</TH><TD>101.0101</TD><TD>164754.5</TD></TR>\n",
       "<TR><TH>11</TH><TD>111.1111</TD><TD>163721.2</TD></TR>\n",
       "<TR><TH>12</TH><TD>121.2121</TD><TD>162732.6</TD></TR>\n",
       "<TR><TH>13</TH><TD>131.3131</TD><TD>161785.7</TD></TR>\n",
       "<TR><TH>14</TH><TD>141.4141</TD><TD>160877.4</TD></TR>\n",
       "<TR><TH>15</TH><TD>151.5152</TD><TD>160004.8</TD></TR>\n",
       "<TR><TH>16</TH><TD>161.6162</TD><TD>159168.1</TD></TR>\n",
       "<TR><TH>17</TH><TD>171.7172</TD><TD>158370</TD></TR>\n",
       "<TR><TH>18</TH><TD>181.8182</TD><TD>157612.4</TD></TR>\n",
       "<TR><TH>19</TH><TD>191.9192</TD><TD>156895.7</TD></TR>\n",
       "<TR><TH>20</TH><TD>202.0202</TD><TD>156221.7</TD></TR>\n",
       "<TR><TH>21</TH><TD>212.1212</TD><TD>155597.5</TD></TR>\n",
       "<TR><TH>22</TH><TD>222.2222</TD><TD>155035.1</TD></TR>\n",
       "<TR><TH>23</TH><TD>232.3232</TD><TD>154544.5</TD></TR>\n",
       "<TR><TH>24</TH><TD>242.4242</TD><TD>154136</TD></TR>\n",
       "<TR><TH>25</TH><TD>252.5253</TD><TD>153819.1</TD></TR>\n",
       "<TR><TH>26</TH><TD>262.6263</TD><TD>153601.5</TD></TR>\n",
       "<TR><TH>27</TH><TD>272.7273</TD><TD>153490.6</TD></TR>\n",
       "<TR><TH>28</TH><TD>282.8283</TD><TD>153495.8</TD></TR>\n",
       "<TR><TH>29</TH><TD>292.9293</TD><TD>153625.1</TD></TR>\n",
       "<TR><TH>30</TH><TD>303.0303</TD><TD>153883.2</TD></TR>\n",
       "<TR><TH>31</TH><TD>313.1313</TD><TD>154271.1</TD></TR>\n",
       "<TR><TH>32</TH><TD>323.2323</TD><TD>154790.1</TD></TR>\n",
       "<TR><TH>33</TH><TD>333.3333</TD><TD>155439.9</TD></TR>\n",
       "<TR><TH>34</TH><TD>343.4343</TD><TD>156214.4</TD></TR>\n",
       "<TR><TH>35</TH><TD>353.5354</TD><TD>157106.1</TD></TR>\n",
       "<TR><TH>36</TH><TD>363.6364</TD><TD>158110.2</TD></TR>\n",
       "<TR><TH>37</TH><TD>373.7374</TD><TD>159223.1</TD></TR>\n",
       "<TR><TH>38</TH><TD>383.8384</TD><TD>160440.6</TD></TR>\n",
       "<TR><TH>39</TH><TD>393.9394</TD><TD>161758.9</TD></TR>\n",
       "<TR><TH>40</TH><TD>404.0404</TD><TD>163170.9</TD></TR>\n",
       "<TR><TH>41</TH><TD>414.1414</TD><TD>164667.6</TD></TR>\n",
       "<TR><TH>42</TH><TD>424.2424</TD><TD>166242.1</TD></TR>\n",
       "<TR><TH>43</TH><TD>434.3434</TD><TD>167892.6</TD></TR>\n",
       "<TR><TH>44</TH><TD>444.4444</TD><TD>169621.3</TD></TR>\n",
       "<TR><TH>45</TH><TD>454.5455</TD><TD>171430.5</TD></TR>\n",
       "<TR><TH>46</TH><TD>464.6465</TD><TD>173321.7</TD></TR>\n",
       "<TR><TH>47</TH><TD>474.7475</TD><TD>175294</TD></TR>\n",
       "<TR><TH>48</TH><TD>484.8485</TD><TD>177343</TD></TR>\n",
       "<TR><TH>49</TH><TD>494.9495</TD><TD>179461.4</TD></TR>\n",
       "<TR><TH>50</TH><TD>505.0505</TD><TD>181633.6</TD></TR>\n",
       "<TR><TH>51</TH><TD>515.1515</TD><TD>183842.4</TD></TR>\n",
       "<TR><TH>52</TH><TD>525.2525</TD><TD>186073.3</TD></TR>\n",
       "<TR><TH>53</TH><TD>535.3535</TD><TD>188311.4</TD></TR>\n",
       "<TR><TH>54</TH><TD>545.4545</TD><TD>190535.5</TD></TR>\n",
       "<TR><TH>55</TH><TD>555.5556</TD><TD>192717.8</TD></TR>\n",
       "<TR><TH>56</TH><TD>565.6566</TD><TD>194829.7</TD></TR>\n",
       "<TR><TH>57</TH><TD>575.7576</TD><TD>196850.6</TD></TR>\n",
       "<TR><TH>58</TH><TD>585.8586</TD><TD>198770.8</TD></TR>\n",
       "<TR><TH>59</TH><TD>595.9596</TD><TD>200588.7</TD></TR>\n",
       "<TR><TH>60</TH><TD>606.0606</TD><TD>202308.2</TD></TR>\n",
       "<TR><TH>61</TH><TD>616.1616</TD><TD>203937.8</TD></TR>\n",
       "<TR><TH>62</TH><TD>626.2626</TD><TD>205487.8</TD></TR>\n",
       "<TR><TH>63</TH><TD>636.3636</TD><TD>206970.1</TD></TR>\n",
       "<TR><TH>64</TH><TD>646.4646</TD><TD>208398.8</TD></TR>\n",
       "<TR><TH>65</TH><TD>656.5657</TD><TD>209795</TD></TR>\n",
       "<TR><TH>66</TH><TD>666.6667</TD><TD>211183.5</TD></TR>\n",
       "<TR><TH>67</TH><TD>676.7677</TD><TD>212588.7</TD></TR>\n",
       "<TR><TH>68</TH><TD>686.8687</TD><TD>214033</TD></TR>\n",
       "<TR><TH>69</TH><TD>696.9697</TD><TD>215536.2</TD></TR>\n",
       "<TR><TH>70</TH><TD>707.0707</TD><TD>217116.3</TD></TR>\n",
       "<TR><TH>71</TH><TD>717.1717</TD><TD>218790.4</TD></TR>\n",
       "<TR><TH>72</TH><TD>727.2727</TD><TD>220570.5</TD></TR>\n",
       "<TR><TH>73</TH><TD>737.3737</TD><TD>222459.8</TD></TR>\n",
       "<TR><TH>74</TH><TD>747.4747</TD><TD>224453.3</TD></TR>\n",
       "<TR><TH>75</TH><TD>757.5758</TD><TD>226541.5</TD></TR>\n",
       "<TR><TH>76</TH><TD>767.6768</TD><TD>228714.8</TD></TR>\n",
       "<TR><TH>77</TH><TD>777.7778</TD><TD>230966.8</TD></TR>\n",
       "<TR><TH>78</TH><TD>787.8788</TD><TD>233297.7</TD></TR>\n",
       "<TR><TH>79</TH><TD>797.9798</TD><TD>235712.1</TD></TR>\n",
       "<TR><TH>80</TH><TD>808.0808</TD><TD>238217.1</TD></TR>\n",
       "<TR><TH>81</TH><TD>818.1818</TD><TD>240817.4</TD></TR>\n",
       "<TR><TH>82</TH><TD>828.2828</TD><TD>243512.5</TD></TR>\n",
       "<TR><TH>83</TH><TD>838.3838</TD><TD>246296.3</TD></TR>\n",
       "<TR><TH>84</TH><TD>848.4848</TD><TD>249159</TD></TR>\n",
       "<TR><TH>85</TH><TD>858.5859</TD><TD>252085.3</TD></TR>\n",
       "<TR><TH>86</TH><TD>868.6869</TD><TD>255057.4</TD></TR>\n",
       "<TR><TH>87</TH><TD>878.7879</TD><TD>258056.8</TD></TR>\n",
       "<TR><TH>88</TH><TD>888.8889</TD><TD>261062.8</TD></TR>\n",
       "<TR><TH>89</TH><TD>898.9899</TD><TD>264048.1</TD></TR>\n",
       "<TR><TH>90</TH><TD>909.0909</TD><TD>266983</TD></TR>\n",
       "<TR><TH>91</TH><TD>919.1919</TD><TD>269839.3</TD></TR>\n",
       "<TR><TH>92</TH><TD>929.2929</TD><TD>272594.3</TD></TR>\n",
       "<TR><TH>93</TH><TD>939.3939</TD><TD>275229.1</TD></TR>\n",
       "<TR><TH>94</TH><TD>949.4949</TD><TD>277728</TD></TR>\n",
       "<TR><TH>95</TH><TD>959.596</TD><TD>280081.2</TD></TR>\n",
       "<TR><TH>96</TH><TD>969.697</TD><TD>282284.4</TD></TR>\n",
       "<TR><TH>97</TH><TD>979.798</TD><TD>284338.2</TD></TR>\n",
       "<TR><TH>98</TH><TD>989.899</TD><TD>286241.5</TD></TR>\n",
       "<TR><TH>99</TH><TD>1000</TD><TD>287991.6</TD></TR>\n",
       "</TABLE>"
      ],
      "text/plain": [
       "class=Field name=Unnamed description=[v0,y0] implementation=class=FieldImplementation name=Unnamed mesh=class=Mesh name=1D_Grid dimension=1 vertices=class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=100 dimension=1 data=[[0],[10.101],[20.202],[30.303],[40.404],[50.5051],[60.6061],[70.7071],[80.8081],[90.9091],[101.01],[111.111],[121.212],[131.313],[141.414],[151.515],[161.616],[171.717],[181.818],[191.919],[202.02],[212.121],[222.222],[232.323],[242.424],[252.525],[262.626],[272.727],[282.828],[292.929],[303.03],[313.131],[323.232],[333.333],[343.434],[353.535],[363.636],[373.737],[383.838],[393.939],[404.04],[414.141],[424.242],[434.343],[444.444],[454.545],[464.646],[474.747],[484.848],[494.949],[505.051],[515.152],[525.253],[535.354],[545.455],[555.556],[565.657],[575.758],[585.859],[595.96],[606.061],[616.162],[626.263],[636.364],[646.465],[656.566],[666.667],[676.768],[686.869],[696.97],[707.071],[717.172],[727.273],[737.374],[747.475],[757.576],[767.677],[777.778],[787.879],[797.98],[808.081],[818.182],[828.283],[838.384],[848.485],[858.586],[868.687],[878.788],[888.889],[898.99],[909.091],[919.192],[929.293],[939.394],[949.495],[959.596],[969.697],[979.798],[989.899],[1000]] simplices=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9,10],[10,11],[11,12],[12,13],[13,14],[14,15],[15,16],[16,17],[17,18],[18,19],[19,20],[20,21],[21,22],[22,23],[23,24],[24,25],[25,26],[26,27],[27,28],[28,29],[29,30],[30,31],[31,32],[32,33],[33,34],[34,35],[35,36],[36,37],[37,38],[38,39],[39,40],[40,41],[41,42],[42,43],[43,44],[44,45],[45,46],[46,47],[47,48],[48,49],[49,50],[50,51],[51,52],[52,53],[53,54],[54,55],[55,56],[56,57],[57,58],[58,59],[59,60],[60,61],[61,62],[62,63],[63,64],[64,65],[65,66],[66,67],[67,68],[68,69],[69,70],[70,71],[71,72],[72,73],[73,74],[74,75],[75,76],[76,77],[77,78],[78,79],[79,80],[80,81],[81,82],[82,83],[83,84],[84,85],[85,86],[86,87],[87,88],[88,89],[89,90],[90,91],[91,92],[92,93],[93,94],[94,95],[95,96],[96,97],[97,98],[98,99]] values=class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=100 dimension=1 description=[y0] data=[[177479],[176009],[174582],[173203],[171870],[170581],[169334],[168126],[166958],[165833],[164754],[163721],[162733],[161786],[160877],[160005],[159168],[158370],[157612],[156896],[156222],[155597],[155035],[154544],[154136],[153819],[153602],[153491],[153496],[153625],[153883],[154271],[154790],[155440],[156214],[157106],[158110],[159223],[160441],[161759],[163171],[164668],[166242],[167893],[169621],[171431],[173322],[175294],[177343],[179461],[181634],[183842],[186073],[188311],[190535],[192718],[194830],[196851],[198771],[200589],[202308],[203938],[205488],[206970],[208399],[209795],[211183],[212589],[214033],[215536],[217116],[218790],[220571],[222460],[224453],[226542],[228715],[230967],[233298],[235712],[238217],[240817],[243512],[246296],[249159],[252085],[255057],[258057],[261063],[264048],[266983],[269839],[272594],[275229],[277728],[280081],[282284],[284338],[286241],[287992]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_E.getRealization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de noter que les processus et variables aléatoires doivent être définies à partir du module \n",
    "NdGaussianProcessConstructor, qui contient les classes suivantes : \n",
    "###### Classe pour construire un champ stochastique : \n",
    "> NdGaussianProcessConstructor.NdGaussianProcessConstructor() \n",
    "###### Classe pour construire une variables aléatoire  : \n",
    "> NdGaussianProcessConstructor.NormalDistribution() ## Classe openturns.Normal() suchargée\n",
    "###### Classe pour construire un vecteur de variables aléatoires normales : \n",
    "> NdGaussianProcessConstructor.RandomNormalVector() ## Classe openturns.PythonRandomVector surchargée. Cette dernière est utilisée en interne par NdGaussianProcessConstructor.\n",
    "\n",
    "**Finalement, l'autre particularité du NdGaussianProcessConstructor, est d'utiliser un objet _numpy.memmap_ modifiée, qui enregistre les échantillons de processus gaussiens sous forme de fichier temporaire dans le directoire d'utilisation des codes et les éfface en sortant du code**\n",
    "\n",
    "L'on définit ensuite les variables de sortie. Il faut connaître l'ordre dans lequel la fonction renvoie ses resultats connaitre leur nom comme leur dimension. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(spsa)\n",
    "outputVariables = {'out1' :\n",
    "                   {\n",
    "                         'name'     : 'VonMisesStress',\n",
    "                         'position' : 0,\n",
    "                         'shape'    : (100,)  \n",
    "                    },\n",
    "                   'out2' :\n",
    "                   {\n",
    "                        'name'      : 'maxDeflection',\n",
    "                        'position'  : 1,\n",
    "                        'shape'     : (1,)\n",
    "                   }\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite, on crée une instance pour l'analyse de sensibilité.\n",
    "Il faut donner en entrée une liste contenant les procéssus et les variables aléatoires **dans l'ordre** dans lequel la fonction les recoit. \n",
    "\n",
    "*Pour cela il faut aussi connaître l'ordre des variables d'entrée de la fonction et leur nombre.*\n",
    "\n",
    "**Ces fonctions sont celles qui prennent entrée des champs aléatoires (vecteurs et matrices, de type *list ou numpy*) et variables aléatoire (scalaires (vecteurs 1D pour le multiprocessing)) et non pas les fonctions prennant en entrée les variables aléatoires issues de la décomposition de la Karhunen Loeve, qui elles sont construites en interne dans la classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Variables are (without Karhunen Loeve Decomposition) :\n",
      " E_ D_ FP FN \n",
      "\n",
      "Output Variables are :\n",
      " ['VonMisesStress', 'maxDeflection'] \n",
      "\n",
      "Composed distribution built with processes and distributions: E_; D_; FP; FN\n",
      "Program initialised, ready for sensitivity analysis.         You can now proceed to prepare the Sobol indices experiment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processesDistributions = [process_E, process_D, RV_Fpos, RV_Fnorm]\n",
    "# We also the need the two functions of the model (one for samples, the other for single evaluations)\n",
    "# In our case, as our model is defined as a class, we have to first create the model, \n",
    "# but it also could just be just two functions taking as an input the fields and RVs\n",
    "soloFunction   = None\n",
    "sampleFunction = PBE.batchEval\n",
    "##\n",
    "size           = 10000 ## Number of samples for our sobol indicies experiment (kept low here to make things faster)\n",
    "## It is sufficient just to pass one of the functions \n",
    "processSensitivityAnalysis = spsa.StochasticProcessSensitivityAnalysis(processesDistributions, \n",
    "                                                                       outputVariables,\n",
    "                                                                       sampleFunction,\n",
    "                                                                       soloFunction,\n",
    "                                                                       size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une vue du dictionnaire intermédiaire qui est crée une fois les processus et variables aléatoires d'entrées définies :\n",
    "\n",
    "On voit que la position des processus dans les arguments de la fonction d'entrée est enregistrée dans le dictionnaire dans la clé *position* et viennent de la manière de laquelle on a mis les VA et Processus dans le vecteur inputVarList. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite, grace à l'intermédiaire de la classe ot.SobolIndiciesExperiment, on génère les' variables aléatoires d'entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation types are:\n",
      "1 : Random (default)\n",
      "2 : LHS\n",
      "\n",
      "3 : LowDiscrepancySequence\n",
      "4 : SimulatedAnnealingLHS\n",
      "You choose Random generation\n",
      "number of samples for sobol experiment = 60000 \n",
      "\n",
      "input design shape is:  (60000, 27)\n",
      "DOING EVAL!!!\n",
      "calling sample function 000\n",
      "Lifting\n",
      "Before loop OK, input dim is 4\n",
      "fieldPositions are [0, 1]\n",
      "wtf\n",
      "idxStpPrev= 0 idxStp= 9 k= 0\n",
      "lifting to field\n",
      "lifted\n",
      "Appended\n",
      "wtf\n",
      "idxStpPrev= 9 idxStp= 25 k= 1\n",
      "lifting to field\n",
      "got exception InvalidDimensionException : Expected coefficients of dimension 16 got 17\n"
     ]
    }
   ],
   "source": [
    "processSensitivityAnalysis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processSensitivityAnalysis._wrappedFunction.StochasticProcessList[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ensuite on récupère les sorties associées aux entrées génerées. \n",
    "L'idée du postprocessing est d'identifier si dans les sorties il y a des valeurs de type np.nan, et de refaire les experiences manquantes tant qu'il y a des np.nan de présents.\n",
    "\n",
    "**Ceci crée quelques problèmes : En effet, si le calcul numérique n'a pas pu aboutir avec une certaine réalisation des variables en entrée, est-ce que cela veut dire que cette réalisation est défaillante? Va-t-on l'inclure dans le cas du calcul de la défaillance ou de la sensibilité? Car si on l'inclut pas, il se peut qu'on oublie un nombre conséquent de modes défaillants. Solution : changer le modèle informatique et le rendre robuste à ces erreurs, ou faire une étude précise avec ces réalisation particulières.**\n",
    "\n",
    "\n",
    "La solution retenue pour génerer les experiences manquantes est d'itérer au dessus de chaque index de la sortie ou se trouvent les nans, de refaire une experience de sobol de taille 1 ( donc qui renverra d+2 valeurs, avec d la dimension de l'entrée), de générer les sorties correspondant aux entrées (recommencer si il s'y trouve un np.nan), et de remplacer les d+2 valeurs du inputDesign d'entrée avec celles que l'on vient de regénérer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le *timing* vient de la classe ***custum_wraps***, qui est pour l'instant assez inutile, mais permet de prendre en main les décorateurs...\n",
    "\n",
    "Une fois le _output design_ generé, l'on peut faire l'analyse de sensibilité sur le model.\n",
    "Pour ce faire, l'on utilise la fonction ***self.getSobolIndiciesKLCoefs***.\n",
    "La fonction ne renvoie pas directement les indices de sobol, mais bien des champs d'objets ***openTURNS.SaltelliSensitivityAlgorithm*** ou ***openTURNS.MartinezSensitivityAlgorithm*** ou ***openTURNS.JansenSensitivityAlgorithm*** ou ***openTURNS.MauntzKucherenkoSensitivityAlgorithm***.\n",
    "\n",
    "Ceci est bien sûr fait dans l'optique de toujours pouvoir accéder à l'entierté des indices de sobol et indices totaux du modèle.\n",
    "Ceci veut aussi dire qu'il manque une dimension pour les champs en sortie, celle des variables d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on calcule les indices de sobol du premier ordre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to use the Saltelli method\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c1551b98f22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessSensitivityAnalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSensitivityAnalysisResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/project_PHIMECA/spsa/spsa/_stochasticprocesssensitivity.py\u001b[0m in \u001b[0;36mgetSensitivityAnalysisResults\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    456\u001b[0m ['Jansen','Saltelli','Mauntz-Kucherenko','Martinez']'''\n\u001b[1;32m    457\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You have chosen to use the'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputDesignList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'distinct outputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0msensitivityAnalysisDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputVariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "processSensitivityAnalysis.getSensitivityAnalysisResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'on peut récuperer ces indices du premier ordre dans ***self.processSensitivityAnalysis.sensitivityResults.firstOrderIndices***\n",
    "Matplotlib permet de facilement visualiser ces indices. Néanmoins, cette visualisation est pour l'instant peu pertinente, puisque l'on visualise chaque variables aléatoire de Karhunen Loeve individuellement, alors qu'il nous faut encore combiner ces dernières pour que l'indice de sobol soit représentatif du champ stochastique consideré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processSensitivityAnalysis.SensitivityAnalysisResults['VonMisesStress'].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processSensitivityAnalysis.SensitivityAnalysisResults['maxDeflection'].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
