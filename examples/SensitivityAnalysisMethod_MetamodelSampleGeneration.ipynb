{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity analysis on models governed by stochastic fields :\n",
    "## Analysis & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Date: 14.10.20\n",
    "- Author: K. A. Simady "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aim of the notebook : present the methods already developed as well as a simple example, and compare the already known methods to the ones developed. \n",
    "- **Theme :** Sensitivity analysis of models taking as an input scalar random variables, as well as random stochastic fields. \n",
    "- **Example :** Model of a beam being supported on both ends and subject to a point force. Five quantities are subject to uncertainties : \n",
    "    - The diameter D_ of the section of the beam is varying along a one dimensional field along the axis of the beam. \n",
    "    - The Young Modulus E_ is also varying stochastically along the same axis\n",
    "    - The position of the application point of the force FPos is following a scalar normal law centered on the beams middle point. \n",
    "    - The norm of the force vector FNorm is also follwing a scalar normal law centered around 100N \n",
    "    - The global densitiy of the beam which is also determined by a scalar normal law centered around the materials real density\n",
    "- **Method :** Roughly, the method consist in reexpressing the model (which was taking as inputs **Fields** & **Scalars**) as a new model only dependent of a **Scalar vector**. This is made possible through the usage of the **Karhunen-Loeve decomposition**, thanks to which one can freely express a field generated by a stochastic process of known parameters as a vector of scalars. This decomposition is analogous to the **Fourier** decomposition. Once the model is re-expressed a metamodel is built using either krieging or polynomial chaos. Then the sensitivity analysis is done on this metamodel, in hope that it behaves as the real model. This will be tested here.\n",
    "- **Application :** This method is developed to be used to analyse the model of a aeronautics grade heat exchanger, but this example will not be presented here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba not installed.\n",
      "You can install numba if you want to speed up a bit the simulations\n",
      "len vertices is: 101\n"
     ]
    }
   ],
   "source": [
    "# Let's first import the necessary modules. \n",
    "# Base modules :\n",
    "import os\n",
    "from collections.abc import Sequence, Iterable\n",
    "import numpy as np\n",
    "import openturns as ot\n",
    "import pandas as pd\n",
    "# Phimeca's modules :\n",
    "#import pythontools as pt # tools created for krieging, pce and other stuff... \n",
    "# Own modules : \n",
    "import klfs # integration of the codes developed ... \n",
    "# Example Model :\n",
    "import dummyBeamModel as MODEL # Could be any model really... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The inputs to our model are the 5 uncertain variables, which effects we try to measure. As for the Karhunen-Loeve decomposition the parameters of the stochastic process must be known (scale, amplitude, autocorrelation function) we will first define those. \n",
    "- Only two of our 5 inputs are stochastic fields, but we need to also express the other ones as fields. To achieve this, we can think about a scalar as the first value of a constant stochastic_field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's define our processes :\n",
    "- As only the autocovariance function and the mesh is needed for the **Karhunen Loeve** decomposition, we have no need to neither define our gaussian processes nor to set a trend function. This has some implications :\n",
    "    - **The trend function was as a constant to represent the mean value of our process. As it is no longer present, in the decomposition, we have to directly add the means inside of our model and consider the inputs as sole perturbations of the mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define the mesh, as it is the same for all the processes, random variables and the finite elements of the beam itself. \n",
    "dimension = 1\n",
    "NElem = [99]\n",
    "mesher = ot.IntervalMesher(NElem)\n",
    "lowerBound = [0] #mm\n",
    "upperBound = [1000] #mm\n",
    "interval = ot.Interval(lowerBound,upperBound)\n",
    "mesh = mesher.build(interval)\n",
    "# 100 elements of 10 mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>MaternModel(scale=[300], amplitude=[10500], nu=4.33333)</p>"
      ],
      "text/plain": [
       "class=MaternModel scale=class=Point name=Unnamed dimension=1 values=[300] amplitude=class=Point name=Unnamed dimension=1 values=[10500] nu=4.33333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First process decomposition : Stochastic young's modulus \n",
    "amplitude0 = [210000*.05]*dimension # Mean : 210000 MPaa\n",
    "scale0 = [300]*dimension \n",
    "nu0 = 13/3\n",
    "model0 = ot.MaternModel(scale0, amplitude0, nu0)\n",
    "\n",
    "process=ot.GaussianProcess(model0, mesh)\n",
    "\n",
    "# Karhunen Loeve decomposition of process \n",
    "algorithm = ot.KarhunenLoeveP1Algorithm(mesh, model0, 1e-3)\n",
    "#algorithm.setNbModes(6)\n",
    "algorithm.run()\n",
    "resultsE = algorithm.getResult()\n",
    "resultsE.setName('E_')\n",
    "resultsE.getCovarianceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second process decomposition : Stochastic Diameter\n",
    "amplitude = [10*.05]*dimension # Mean 10 mm\n",
    "scale = [250]*dimension\n",
    "nu = 7.4/3\n",
    "model1 = ot.MaternModel(scale, amplitude, nu)\n",
    "algorithm = ot.KarhunenLoeveP1Algorithm(mesh, model1, 1e-3)\n",
    "#algorithm.setNbModes(6)\n",
    "algorithm.run()\n",
    "resultsD = algorithm.getResult()\n",
    "resultsD.setName('D_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two scalar random variables : \n",
    "# random variable for the position of the force (mm) \n",
    "sigma_f      = 500*.05\n",
    "RV_Fpos = ot.Normal(500, sigma_f)\n",
    "RV_Fpos.setName('FPos')\n",
    "# random variable for the norm of the force (N)\n",
    "sigma_Fnor    = 100*.05\n",
    "RV_Fnorm  = ot.Normal(100, sigma_Fnor)\n",
    "RV_Fnorm.setName('FNorm')\n",
    "\n",
    "# With the modifs, we can now utilize directly the Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once all the processes are defined, created and decomposed thanks to Karhunen Loeve, we use our newly created class **AggregatedKarhunenLoeveResults**. This class is the link between our reduced normal centered law vector, being one dimensional, and our dimension of arbitrary fields and scalars (so either a-dimensional or multi-dimensional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfKLRes = [resultsE, resultsD, RV_Fpos, RV_Fnorm]\n",
    "AggregatedKLRes = klfs.AggregatedKarhunenLoeveResults(listOfKLRes)\n",
    "AggregatedKLRes.setMean(0, 210000) # At other indices the means are initialized from the distributions\n",
    "AggregatedKLRes.setMean(1, 10) \n",
    "AggregatedKLRes.setLiftWithMean(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Depending on how our model was defined, some more steps may be performed if necessary. In our case, to initialize our model, we first have to pass it a mesh from which dimensions it builds its finite element representation, entirely based on the mesh on which the processes where defined. Then we differentiate our model into two functions, one that works on multiple inputs with multiprocessing and one only for single evaluations. **This differntation step is optional, only one of the two functions is needed**\n",
    "- **The functions as well as the aggregated Karhunen Loeve Results object are passed to a other newly defined class: KarhunenLoeveGeneralizedFunctionWrapper :\n",
    "    > As this class has access to the Karhunen-Loeve decomposition (which is as said the link between our differnt dimensions) and the model to analyse, this wrapper allows us to get a other view of the model, a view where the model is only dependent of a input vector of values following a centered reduced normal law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class = ComposedKarhunenLoeveResultsAndDistributions| name = Unnamed| Aggregation Order = 4| Threshold = 0.001| Covariance Model 0 = class=MaternModel scale=class=Point name=Unnamed dimension=1 values=[300] amplitude=class=Point name=Unnamed dimension=1 values=[10500] nu=4.33333| Covariance Model 1 = class=MaternModel scale=class=Point name=Unnamed dimension=1 values=[250] amplitude=class=Point name=Unnamed dimension=1 values=[0.5] nu=2.46667| Covariance Model 2 = None| Covariance Model 3 = None| Eigen Value 0 = class=Point name=Unnamed dimension=7 values=[6.25878e+10,3.11591e+10,1.14197e+10,3.55608e+09,1.04551e+09,3.09588e+08,9.56649e+07]| Eigen Value 1 = class=Point name=Unnamed dimension=10 values=[121.91,70.6145,32.8343,13.8746,5.79651,2.50434,1.14062,0.550531,0.281169,0.151298]| Eigen Value 2 = None| Eigen Value 3 = None| Mesh 0 = class=Mesh name=Unnamed dimension=1 vertices=class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=100 dimension=1 | Mesh 1 = class=Mesh name=Unnamed dimension=1 vertices=class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=100 dimension=1 | Mesh 2 = None| Mesh 3 = None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definition of the model :\n",
    "_MODEL = MODEL.Beam()\n",
    "\n",
    "# initialization of the function wrapper : \n",
    "FUNC = klfs.KarhunenLoeveGeneralizedFunctionWrapper(\n",
    "                                AggregatedKarhunenLoeveResults = AggregatedKLRes,\n",
    "                                func        = None, \n",
    "                                func_sample = _MODEL.batchEval,\n",
    "                                n_outputs   = 2) #We have to define the number of elements in the tuple the model returns !!!!!!!!!!!\n",
    "AggregatedKLRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our model and input parameters we can begin to design our DOE (Design of experiment). We will generate mutiple DOEs, as we want to compare multiple methods together. \n",
    "- **As we know that ALL the components of the vector entering into our wrapped functions are following a centered resuced normal law we have different ways of generating our DOE.**\n",
    "    - First of all we need 3 types of DOEs :\n",
    "        - One for the krieging with 100 points : This one will be generated with the LHS sampling method. For this generation we do not need any class in particular. \n",
    "            - => For this sample we also need the response (or output) of the finite element model (FUNC) \n",
    "        - Two for the calculus of the sobol indices. These ones will be much bigger and will only follow a random sampling method. Only one of these samples will be evaluated on the finite element model. The other one will be evaluated on the krieging metamodel to compare the sobol indices in both cases. \n",
    "    - As we want to test the inluence of the different parameters having an influence we will prepaper multiple DOEs per type of DOE. :\n",
    "        - For the first type (the krieging model):\n",
    "            - one DOE with 50 points following the LHS sampling method    | SEED : 130875 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 100 points following the LHS sampling method   | SEED : 409484 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 200 points following the LHS sampling method   | SEED : 224409 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "\n",
    "        - For the second and third type (sobol on the fem model):\n",
    "            - one DOE with 1000 points following a random sampling method | SEED : 248214 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 2000 points following a random sampling method | SEED : 720442 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 4000 points following a random sampling method | SEED : 109242 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer\n",
    "\n",
    "\n",
    "# Little helper class for optimized lhs :\n",
    "@timer\n",
    "def optimizedLHS(distribution, size, seed):\n",
    "    ot.RandomGenerator.SetSeed(seed)\n",
    "    lhs = ot.LHSExperiment(distribution, size, True, True)\n",
    "    lhs_optimise = ot.SimulatedAnnealingLHS(lhs)\n",
    "    lhs_sample = lhs_optimise.generate()\n",
    "    return lhs_sample\n",
    "\n",
    "@timer\n",
    "def getSample(distribution, size, seed):\n",
    "    ot.RandomGenerator.SetSeed(seed)\n",
    "    sample = distribution.getSample(size)\n",
    "    sample.setDescription(distribution.getDescription())\n",
    "    return sample\n",
    "\n",
    "@timer \n",
    "def getSobolExperiment(size, seed, secondOrder = False):\n",
    "    ot.RandomGenerator.SetSeed(seed)    \n",
    "    experiment = klfs.KarhunenLoeveSobolIndicesExperiment(AggregatedKLRes, size, secondOrder)\n",
    "    sobolExp = experiment.generate()\n",
    "    return sobolExp, experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our design of experiment, we will need some data about our KL decomposition, namely the order of decomposition and a random normal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>ComposedDistribution(Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), IndependentCopula(dimension = 19))</p>"
      ],
      "text/plain": [
       "class=ComposedDistribution name=ComposedDistribution dimension=19 copula=class=IndependentCopula name=IndependentCopula dimension=19 marginal[0]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[1]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[2]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[3]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[4]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[5]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[6]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[7]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[8]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[9]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[10]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[11]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[12]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[13]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[14]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[15]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[16]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[17]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[18]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nModes = AggregatedKLRes.getSizeModes()  # the number of elements in the input vector of our KL wrapped model\n",
    "randNormVect = ot.ComposedDistribution([ot.Normal()] * nModes)  # \n",
    "randNormVect.setDescription(AggregatedKLRes._getModeDescription())\n",
    "randNormVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples A and B of size 10 and dimension 19\n",
      "Experiment of size 60 and dimension 19\n",
      "Elapsed time: 0.0013 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  0],\n",
       "       [10,  1],\n",
       "       [10,  2],\n",
       "       [10,  3],\n",
       "       [10,  4],\n",
       "       [10,  5],\n",
       "       [10,  6],\n",
       "       [10,  7],\n",
       "       [10,  8],\n",
       "       [10,  9],\n",
       "       [10, 10],\n",
       "       [10, 11],\n",
       "       [10, 12],\n",
       "       [10, 13],\n",
       "       [10, 14],\n",
       "       [10, 15],\n",
       "       [10, 16],\n",
       "       [10, 17],\n",
       "       [10, 18],\n",
       "       [11,  0],\n",
       "       [11,  1],\n",
       "       [11,  2],\n",
       "       [11,  3],\n",
       "       [11,  4],\n",
       "       [11,  5],\n",
       "       [11,  6],\n",
       "       [11,  7],\n",
       "       [11,  8],\n",
       "       [11,  9],\n",
       "       [11, 10],\n",
       "       [11, 11],\n",
       "       [11, 12],\n",
       "       [11, 13],\n",
       "       [11, 14],\n",
       "       [11, 15],\n",
       "       [11, 16],\n",
       "       [11, 17],\n",
       "       [11, 18],\n",
       "       [12,  0],\n",
       "       [12,  1],\n",
       "       [12,  2],\n",
       "       [12,  3],\n",
       "       [12,  4],\n",
       "       [12,  5],\n",
       "       [12,  6],\n",
       "       [12,  7],\n",
       "       [12,  8],\n",
       "       [12,  9],\n",
       "       [12, 10],\n",
       "       [12, 11],\n",
       "       [12, 12],\n",
       "       [12, 13],\n",
       "       [12, 14],\n",
       "       [12, 15],\n",
       "       [12, 16],\n",
       "       [12, 17],\n",
       "       [12, 18],\n",
       "       [13,  0],\n",
       "       [13,  1],\n",
       "       [13,  2],\n",
       "       [13,  3],\n",
       "       [13,  4],\n",
       "       [13,  5],\n",
       "       [13,  6],\n",
       "       [13,  7],\n",
       "       [13,  8],\n",
       "       [13,  9],\n",
       "       [13, 10],\n",
       "       [13, 11],\n",
       "       [13, 12],\n",
       "       [13, 13],\n",
       "       [13, 14],\n",
       "       [13, 15],\n",
       "       [13, 16],\n",
       "       [13, 17],\n",
       "       [13, 18],\n",
       "       [14,  0],\n",
       "       [14,  1],\n",
       "       [14,  2],\n",
       "       [14,  3],\n",
       "       [14,  4],\n",
       "       [14,  5],\n",
       "       [14,  6],\n",
       "       [14,  7],\n",
       "       [14,  8],\n",
       "       [14,  9],\n",
       "       [14, 10],\n",
       "       [14, 11],\n",
       "       [14, 12],\n",
       "       [14, 13],\n",
       "       [14, 14],\n",
       "       [14, 15],\n",
       "       [14, 16],\n",
       "       [14, 17],\n",
       "       [14, 18],\n",
       "       [15,  0],\n",
       "       [15,  1],\n",
       "       [15,  2],\n",
       "       [15,  3],\n",
       "       [15,  4],\n",
       "       [15,  5],\n",
       "       [15,  6],\n",
       "       [15,  7],\n",
       "       [15,  8],\n",
       "       [15,  9],\n",
       "       [15, 10],\n",
       "       [15, 11],\n",
       "       [15, 12],\n",
       "       [15, 13],\n",
       "       [15, 14],\n",
       "       [15, 15],\n",
       "       [15, 16],\n",
       "       [15, 17],\n",
       "       [15, 18],\n",
       "       [16,  0],\n",
       "       [16,  1],\n",
       "       [16,  2],\n",
       "       [16,  3],\n",
       "       [16,  4],\n",
       "       [16,  5],\n",
       "       [16,  6],\n",
       "       [16,  7],\n",
       "       [16,  8],\n",
       "       [16,  9],\n",
       "       [16, 10],\n",
       "       [16, 11],\n",
       "       [16, 12],\n",
       "       [16, 13],\n",
       "       [16, 14],\n",
       "       [16, 15],\n",
       "       [16, 16],\n",
       "       [16, 17],\n",
       "       [16, 18],\n",
       "       [17,  0],\n",
       "       [17,  1],\n",
       "       [17,  2],\n",
       "       [17,  3],\n",
       "       [17,  4],\n",
       "       [17,  5],\n",
       "       [17,  6],\n",
       "       [17,  7],\n",
       "       [17,  8],\n",
       "       [17,  9],\n",
       "       [17, 10],\n",
       "       [17, 11],\n",
       "       [17, 12],\n",
       "       [17, 13],\n",
       "       [17, 14],\n",
       "       [17, 15],\n",
       "       [17, 16],\n",
       "       [17, 17],\n",
       "       [17, 18],\n",
       "       [18,  0],\n",
       "       [18,  1],\n",
       "       [18,  2],\n",
       "       [18,  3],\n",
       "       [18,  4],\n",
       "       [18,  5],\n",
       "       [18,  6],\n",
       "       [18,  7],\n",
       "       [18,  8],\n",
       "       [18,  9],\n",
       "       [18, 10],\n",
       "       [18, 11],\n",
       "       [18, 12],\n",
       "       [18, 13],\n",
       "       [18, 14],\n",
       "       [18, 15],\n",
       "       [18, 16],\n",
       "       [18, 17],\n",
       "       [18, 18],\n",
       "       [19,  0],\n",
       "       [19,  1],\n",
       "       [19,  2],\n",
       "       [19,  3],\n",
       "       [19,  4],\n",
       "       [19,  5],\n",
       "       [19,  6],\n",
       "       [19,  7],\n",
       "       [19,  8],\n",
       "       [19,  9],\n",
       "       [19, 10],\n",
       "       [19, 11],\n",
       "       [19, 12],\n",
       "       [19, 13],\n",
       "       [19, 14],\n",
       "       [19, 15],\n",
       "       [19, 16],\n",
       "       [19, 17],\n",
       "       [19, 18],\n",
       "       [20,  0],\n",
       "       [20,  1],\n",
       "       [20,  2],\n",
       "       [20,  3],\n",
       "       [20,  4],\n",
       "       [20,  5],\n",
       "       [20,  6],\n",
       "       [21,  0],\n",
       "       [21,  1],\n",
       "       [21,  2],\n",
       "       [21,  3],\n",
       "       [21,  4],\n",
       "       [21,  5],\n",
       "       [21,  6],\n",
       "       [22,  0],\n",
       "       [22,  1],\n",
       "       [22,  2],\n",
       "       [22,  3],\n",
       "       [22,  4],\n",
       "       [22,  5],\n",
       "       [22,  6],\n",
       "       [23,  0],\n",
       "       [23,  1],\n",
       "       [23,  2],\n",
       "       [23,  3],\n",
       "       [23,  4],\n",
       "       [23,  5],\n",
       "       [23,  6],\n",
       "       [24,  0],\n",
       "       [24,  1],\n",
       "       [24,  2],\n",
       "       [24,  3],\n",
       "       [24,  4],\n",
       "       [24,  5],\n",
       "       [24,  6],\n",
       "       [25,  0],\n",
       "       [25,  1],\n",
       "       [25,  2],\n",
       "       [25,  3],\n",
       "       [25,  4],\n",
       "       [25,  5],\n",
       "       [25,  6],\n",
       "       [26,  0],\n",
       "       [26,  1],\n",
       "       [26,  2],\n",
       "       [26,  3],\n",
       "       [26,  4],\n",
       "       [26,  5],\n",
       "       [26,  6],\n",
       "       [27,  0],\n",
       "       [27,  1],\n",
       "       [27,  2],\n",
       "       [27,  3],\n",
       "       [27,  4],\n",
       "       [27,  5],\n",
       "       [27,  6],\n",
       "       [28,  0],\n",
       "       [28,  1],\n",
       "       [28,  2],\n",
       "       [28,  3],\n",
       "       [28,  4],\n",
       "       [28,  5],\n",
       "       [28,  6],\n",
       "       [29,  0],\n",
       "       [29,  1],\n",
       "       [29,  2],\n",
       "       [29,  3],\n",
       "       [29,  4],\n",
       "       [29,  5],\n",
       "       [29,  6],\n",
       "       [30,  7],\n",
       "       [30,  8],\n",
       "       [30,  9],\n",
       "       [30, 10],\n",
       "       [30, 11],\n",
       "       [30, 12],\n",
       "       [30, 13],\n",
       "       [30, 14],\n",
       "       [30, 15],\n",
       "       [30, 16],\n",
       "       [31,  7],\n",
       "       [31,  8],\n",
       "       [31,  9],\n",
       "       [31, 10],\n",
       "       [31, 11],\n",
       "       [31, 12],\n",
       "       [31, 13],\n",
       "       [31, 14],\n",
       "       [31, 15],\n",
       "       [31, 16],\n",
       "       [32,  7],\n",
       "       [32,  8],\n",
       "       [32,  9],\n",
       "       [32, 10],\n",
       "       [32, 11],\n",
       "       [32, 12],\n",
       "       [32, 13],\n",
       "       [32, 14],\n",
       "       [32, 15],\n",
       "       [32, 16],\n",
       "       [33,  7],\n",
       "       [33,  8],\n",
       "       [33,  9],\n",
       "       [33, 10],\n",
       "       [33, 11],\n",
       "       [33, 12],\n",
       "       [33, 13],\n",
       "       [33, 14],\n",
       "       [33, 15],\n",
       "       [33, 16],\n",
       "       [34,  7],\n",
       "       [34,  8],\n",
       "       [34,  9],\n",
       "       [34, 10],\n",
       "       [34, 11],\n",
       "       [34, 12],\n",
       "       [34, 13],\n",
       "       [34, 14],\n",
       "       [34, 15],\n",
       "       [34, 16],\n",
       "       [35,  7],\n",
       "       [35,  8],\n",
       "       [35,  9],\n",
       "       [35, 10],\n",
       "       [35, 11],\n",
       "       [35, 12],\n",
       "       [35, 13],\n",
       "       [35, 14],\n",
       "       [35, 15],\n",
       "       [35, 16],\n",
       "       [36,  7],\n",
       "       [36,  8],\n",
       "       [36,  9],\n",
       "       [36, 10],\n",
       "       [36, 11],\n",
       "       [36, 12],\n",
       "       [36, 13],\n",
       "       [36, 14],\n",
       "       [36, 15],\n",
       "       [36, 16],\n",
       "       [37,  7],\n",
       "       [37,  8],\n",
       "       [37,  9],\n",
       "       [37, 10],\n",
       "       [37, 11],\n",
       "       [37, 12],\n",
       "       [37, 13],\n",
       "       [37, 14],\n",
       "       [37, 15],\n",
       "       [37, 16],\n",
       "       [38,  7],\n",
       "       [38,  8],\n",
       "       [38,  9],\n",
       "       [38, 10],\n",
       "       [38, 11],\n",
       "       [38, 12],\n",
       "       [38, 13],\n",
       "       [38, 14],\n",
       "       [38, 15],\n",
       "       [38, 16],\n",
       "       [39,  7],\n",
       "       [39,  8],\n",
       "       [39,  9],\n",
       "       [39, 10],\n",
       "       [39, 11],\n",
       "       [39, 12],\n",
       "       [39, 13],\n",
       "       [39, 14],\n",
       "       [39, 15],\n",
       "       [39, 16],\n",
       "       [40, 17],\n",
       "       [41, 17],\n",
       "       [42, 17],\n",
       "       [43, 17],\n",
       "       [44, 17],\n",
       "       [45, 17],\n",
       "       [46, 17],\n",
       "       [47, 17],\n",
       "       [48, 17],\n",
       "       [49, 17],\n",
       "       [50, 18],\n",
       "       [51, 18],\n",
       "       [52, 18],\n",
       "       [53, 18],\n",
       "       [54, 18],\n",
       "       [55, 18],\n",
       "       [56, 18],\n",
       "       [57, 18],\n",
       "       [58, 18],\n",
       "       [59, 18]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=getSobolExperiment(10,1584)\n",
    "X = a \n",
    "X_A = X[:10,:]\n",
    "X_An = np.array(X_A)\n",
    "Y_Bn = np.array(X[10:20])\n",
    "X_n = np.array(X)\n",
    "Y = np.zeros(X_n.shape)\n",
    "for i in range(int(X_n.shape[0]/10)):\n",
    "    Y[i*10:(i+1)*10, :] = (X_n[i*10:(i+1)*10, :]==Y_Bn)\n",
    "u=ot.Sample(Y)\n",
    "np.argwhere(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.1181 seconds\n",
      "Elapsed time: 0.4550 seconds\n",
      "Elapsed time: 1.6178 seconds\n",
      "First DOE type done\n",
      "\n",
      "Samples A and B of size 1000 and dimension 19\n",
      "Experiment of size 6000 and dimension 19\n",
      "Elapsed time: 0.0135 seconds\n",
      "Samples A and B of size 2000 and dimension 19\n",
      "Experiment of size 12000 and dimension 19\n",
      "Elapsed time: 0.0177 seconds\n",
      "Samples A and B of size 4000 and dimension 19\n",
      "Experiment of size 24000 and dimension 19\n",
      "Elapsed time: 0.0322 seconds\n",
      "Samples A and B of size 8000 and dimension 19\n",
      "Experiment of size 48000 and dimension 19\n",
      "Elapsed time: 0.0562 seconds\n",
      "Generating samples for the second order indices\n",
      "Samples A and B of size 2000 and dimension 19\n",
      "Experiment for second order generated\n",
      "Experiment of size 20000 and dimension 19\n",
      "Elapsed time: 0.0209 seconds\n",
      "Sobol Samples OK.\n",
      "Elapsed time: 1.5769 seconds\n"
     ]
    }
   ],
   "source": [
    "kg_doe50_130875   = optimizedLHS(randNormVect, 50, 130875)\n",
    "kg_doe100_409484  = optimizedLHS(randNormVect, 100, 409484)\n",
    "kg_doe200_224409  = optimizedLHS(randNormVect, 200, 224409)\n",
    "print('First DOE type done\\n')\n",
    "\n",
    "si_doe1000_248214, expe_doe1000 = getSobolExperiment(1000, 248214)\n",
    "si_doe2000_720442, expe_doe2000 = getSobolExperiment(2000, 720442)\n",
    "si_doe4000_109242, expe_doe4000 = getSobolExperiment(4000, 109242)\n",
    "si_doe8000_439038, expe_doe8000 = getSobolExperiment(8000, 439038)\n",
    "\n",
    "si_sec_doe2000_8291001288, expe_doe2000_sec = getSobolExperiment(2000, 8291001288, True)\n",
    "\n",
    "print('Sobol Samples OK.')\n",
    "\n",
    "valid_doe200_502849 = optimizedLHS(randNormVect, 200, 502849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples A and B of size 10000 and dimension 19\n",
      "Experiment of size 60000 and dimension 19\n",
      "Elapsed time: 0.0806 seconds\n"
     ]
    }
   ],
   "source": [
    "si_doe4000_1092445, expe_doe4000_2 = getSobolExperiment(10000, 1092445)\n",
    "#si_doe50000_3846345, expe_doe50000_3846345 = getSobolExperiment(50000, 3846345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si_doe50000_3846345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field E shape (100, 100)\n",
      "var_Fnor shape (100,)\n",
      "field_E 210055.2129089407 field_D 10.002162804359951 var_Fpos 499.9458882511429 var_Fnor 100.02508378644619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (100, 101)  should be [N,10X] something\n",
      "deflection std deviation  3.7359493428625057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    7.6s finished\n",
      "/home/kramer84/anaconda3/envs/devNAnalysis/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39520/1420596947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFUNC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkg_doe100_409484\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/devNAnalysis/lib/python3.9/site-packages/klfs-0.1-py3.9.egg/klfs/_karhunenLoeveGeneralizedFunctionWrapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/devNAnalysis/lib/python3.9/site-packages/klfs-0.1-py3.9.egg/klfs/_karhunenLoeveGeneralizedFunctionWrapper.py\u001b[0m in \u001b[0;36m_exec_sample\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'did not manage to evaluate batch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__output_backup__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;31m# If the rest fails you can still get the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matLeastList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "test = FUNC(kg_doe100_409484)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp2 = FUNC(si_doe4000_1092445)\n",
    "# resp_doe50000_3846345 = FUNC(si_doe50000_3846345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vonMises = ot.Sample(np.array(np.stack([np.squeeze(np.asarray(resp2[0][i])) for i in range(len(resp2[0]))]))) \n",
    "maxDefl = resp2[1][0]\n",
    "si_doe4000_1092445.exportToCSVFile(os.path.join('./','inp_10000'+'.csv'), ';')\n",
    "vonMises.exportToCSVFile(os.path.join('./','out_10000'+'_VM'+'.csv'), ';')\n",
    "maxDefl.exportToCSVFile(os.path.join('./','out_10000'+'_MD'+'.csv'), ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vonMises_2 = ot.Sample(np.array(np.stack([np.squeeze(np.asarray(resp_doe50000_3846345[0][i])) for i in range(len(resp_doe50000_3846345[0]))]))) \n",
    "#maxDefl_2 = resp_doe50000_3846345[1][0]\n",
    "#si_doe4000_1092445.exportToCSVFile(os.path.join('./','inp_50000'+'.csv'), ';')\n",
    "#vonMises_2.exportToCSVFile(os.path.join('./','out_50000'+'_VM'+'.csv'), ';')\n",
    "#maxDefl_2.exportToCSVFile(os.path.join('./','out_50000'+'_MD'+'.csv'), ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our design of expriments, we're going to evaluate the model on them, to get it's response. Then we're going to all save into csv files in  a folder, and use these as a basis for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOE_names      = ['kg_doe50_130875', 'kg_doe100_409484', 'kg_doe200_224409', 'si_doe1000_248214', 'si_doe2000_720442', \n",
    "                  'val_doe200_502849', 'si_sec_doe2000_8291001288' , 'si_doe4000_109242', 'si_doe8000_439038']\n",
    "DOE_resp_names = ['kg_doe50_130875_resp', 'kg_doe100_409484_resp', 'kg_doe200_224409_resp', 'si_doe1000_248214_resp', 'si_doe2000_720442_resp', \n",
    "                  'val_doe200_502849_resp', 'si_sec_doe2000_8291001288_resp', 'si_doe4000_109242_resp', 'si_doe8000_439038_resp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_DOEs = [kg_doe50_130875,kg_doe100_409484,kg_doe200_224409,si_doe1000_248214,si_doe2000_720442, valid_doe200_502849, si_sec_doe2000_8291001288, si_doe4000_109242, si_doe8000_439038] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './DOE_RESP2'\n",
    "for i, doe in enumerate(l_DOEs):\n",
    "    if not os.path.isfile(os.path.join(folder,DOE_names[i]+'.csv')):\n",
    "        resp = FUNC(doe)\n",
    "        vonMises = ot.Sample(np.array(np.stack([np.squeeze(np.asarray(resp[0][i])) for i in range(len(resp[0]))]))) \n",
    "        maxDefl = resp[1][0]\n",
    "        doe.exportToCSVFile(os.path.join(folder,DOE_names[i]+'.csv'), ';')\n",
    "        vonMises.exportToCSVFile(os.path.join(folder,DOE_resp_names[i]+'_VM'+'.csv'), ';')\n",
    "        maxDefl.exportToCSVFile(os.path.join(folder,DOE_resp_names[i]+'_MD'+'.csv'), ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
