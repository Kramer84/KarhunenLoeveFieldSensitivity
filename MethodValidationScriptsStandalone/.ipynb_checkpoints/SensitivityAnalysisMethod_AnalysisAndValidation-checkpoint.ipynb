{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity analysis on models governed by stochastic fields :\n",
    "## Analysis & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Date: 14.10.20\n",
    "- Author: K. A. Simady "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aim of the notebook : present the methods already developed as well as a simple example, and compare the already known methods to the ones developed. \n",
    "- **Theme :** Sensitivity analysis of models taking as an input scalar random variables, as well as random stochastic fields. \n",
    "- **Example :** Model of a beam being supported on both ends and subject to a point force. Five quantities are subject to uncertainties : \n",
    "    - The diameter D_ of the section of the beam is varying along a one dimensional field along the axis of the beam. \n",
    "    - The Young Modulus E_ is also varying stochastically along the same axis\n",
    "    - The position of the application point of the force FPos is following a scalar normal law centered on the beams middle point. \n",
    "    - The norm of the force vector FNorm is also follwing a scalar normal law centered around 100N \n",
    "    - The global densitiy of the beam which is also determined by a scalar normal law centered around the materials real density\n",
    "- **Method :** Roughly, the method consist in reexpressing the model (which was taking as inputs **Fields** & **Scalars**) as a new model only dependent of a **Scalar vector**. This is made possible through the usage of the **Karhunen-Loeve decomposition**, thanks to which one can freely express a field generated by a stochastic process of known parameters as a vector of scalars. This decomposition is analogous to the **Fourier** decomposition. Once the model is re-expressed a metamodel is built using either krieging or polynomial chaos. Then the sensitivity analysis is done on this metamodel, in hope that it behaves as the real model. This will be tested here.\n",
    "- **Application :** This method is developed to be used to analyse the model of a aeronautics grade heat exchanger, but this example will not be presented here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/simady/anaconda/envs/stochastic_field_env/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# Let's first import the necessary modules. \n",
    "# Base modules :\n",
    "import os\n",
    "from collections.abc import Sequence, Iterable\n",
    "import numpy as np\n",
    "import openturns as ot\n",
    "import pandas as pd\n",
    "# Phimeca's modules :\n",
    "import pythontools as pt # tools created for krieging, pce and other stuff... \n",
    "# Own modules : \n",
    "import KarhunenLoeveFieldSensitivity as klfs # integration of the codes developed ... \n",
    "# Example Model :\n",
    "import PureBeamExample as MODEL # Could be any model really... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The inputs to our model are the 5 uncertain variables, which effects we try to measure. As for the Karhunen-Loeve decomposition the parameters of the stochastic process must be known (scale, amplitude, autocorrelation function) we will first define those. \n",
    "- Only two of our 5 inputs are stochastic fields, but we need to also express the other ones as fields. To achieve this, we can think about a scalar as the first value of a constant stochastic_field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function that transforms a scalar random law and a mesh into a constant stochastic process : \n",
    "def distributionOnMesh(distribution, mesh):\n",
    "    '''Function to transform a scalar distribution into \n",
    "    a constant process defined over a mesh\n",
    "    '''\n",
    "    basis = ot.Basis([ot.SymbolicFunction(['x'],['1'])])\n",
    "    distributionOnMesh = ot.FunctionalBasisProcess(distribution, basis, mesh)\n",
    "    distributionOnMesh.setName(distribution.getName())\n",
    "    return distributionOnMesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's define our processes :\n",
    "- As only the autocovariance function and the mesh is needed for the **Karhunen Loeve** decomposition, we have no need to neither define our gaussian processes nor to set a trend function. This has some implications :\n",
    "    - **The trend function was as a constant to represent the mean value of our process. As it is no longer present, in the decomposition, we have to directly add the means inside of our model and consider the inputs as sole perturbations of the mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define the mesh, as it is the same for all the processes, random variables and the finite elements of the beam itself. \n",
    "dimension = 1\n",
    "NElem = [100]\n",
    "mesher = ot.IntervalMesher(NElem)\n",
    "lowerBound = [0] #mm\n",
    "upperBound = [1000] #mm\n",
    "interval = ot.Interval(lowerBound,upperBound)\n",
    "mesh = mesher.build(interval)\n",
    "# 100 elements of 10 mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First process decomposition : Stochastic young's modulus \n",
    "amplitude0 = [50000]*dimension # Mean : 210000 MPaa\n",
    "scale0 = [300]*dimension \n",
    "nu0 = 13/3\n",
    "model0 = ot.MaternModel(scale0, amplitude0, nu0)\n",
    "# Karhunen Loeve decomposition of process \n",
    "algorithm = ot.KarhunenLoeveP1Algorithm(mesh, model0, 1e-3)\n",
    "algorithm.run()\n",
    "resultsE = algorithm.getResult()\n",
    "resultsE.setName('E_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second process decomposition : Stochastic Diameter\n",
    "amplitude = [.3]*dimension # Mean 10 mm\n",
    "scale = [250]*dimension\n",
    "nu = 7.4/3\n",
    "model1 = ot.MaternModel(scale, amplitude, nu)\n",
    "algorithm = ot.KarhunenLoeveP1Algorithm(mesh, model1, 1e-3)\n",
    "algorithm.run()\n",
    "resultsD = algorithm.getResult()\n",
    "resultsD.setName('D_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three scalar random variables : \n",
    "# random variable for the density of the material (kg/mÂ³)\n",
    "sigma       = 750\n",
    "RV_Rho = ot.Normal(0, sigma)\n",
    "RV_Rho.setName('Rho')\n",
    "# random variable for the position of the force (mm) \n",
    "sigma_f      = 50\n",
    "RV_Fpos = ot.Normal(0, sigma_f)\n",
    "RV_Fpos.setName('FPos')\n",
    "# random variable for the norm of the force (N)\n",
    "sigma_Fnor    = 5.5\n",
    "RV_Fnorm  = ot.Normal(0, sigma_Fnor)\n",
    "RV_Fnorm.setName('FNorm')\n",
    "# Conversion into constant stochastic processes : \n",
    "# Then convert the distributions to processes over a mesh\n",
    "SP_Rho = distributionOnMesh(RV_Rho, mesh)\n",
    "SP_Fpos = distributionOnMesh(RV_Fpos, mesh)\n",
    "SP_Fnorm = distributionOnMesh(RV_Fnorm, mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that our three scalar random variables are expressed as stochastic processes we can decompose them using the KL decomposition **BUT** :\n",
    "    - We shall still not forget to add their means into our model and **we must think to limit the order of decomposition of our process to 1, as we need no more than one scalar variable to express an other scalar.** (Transforms from allmost any law exist into the normal centered law) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition of the process representing the density\n",
    "algorithm0 = ot.KarhunenLoeveP1Algorithm(mesh, SP_Rho.getCovarianceModel())\n",
    "algorithm0.setNbModes(1)\n",
    "algorithm0.run()\n",
    "resultsRho = algorithm0.getResult()\n",
    "resultsRho.setName('Rho_')\n",
    "\n",
    "# Decomposition of the process representing the position of the force\n",
    "algorithm1 = ot.KarhunenLoeveP1Algorithm(mesh, SP_Fpos.getCovarianceModel())\n",
    "algorithm1.setNbModes(1)\n",
    "algorithm1.run()\n",
    "resultsFpos = algorithm1.getResult()\n",
    "resultsFpos.setName('Fpos_')\n",
    "\n",
    "# Decomposition of the process representing the norm of the force\n",
    "algorithm2 = ot.KarhunenLoeveP1Algorithm(mesh, SP_Fnorm.getCovarianceModel())\n",
    "algorithm2.setNbModes(1)\n",
    "algorithm2.run()\n",
    "resultsFnor = algorithm2.getResult()\n",
    "resultsFnor.setName('Fnorm_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once all the processes are defined, created and decomposed thanks to Karhunen Loeve, we use our newly created class **AggregatedKarhunenLoeveResults**. This class is the link between our reduced normal centered law vector, being one dimensional, and our dimension of arbitrary fields and scalars (so either a-dimensional or multi-dimensional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfKLRes = [resultsE, resultsD, resultsRho, resultsFpos, resultsFnor]\n",
    "AggregatedKLRes = klfs.AggregatedKarhunenLoeveResults(listOfKLRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Depending on how our model was defined, some more steps may be performed if necessary. In our case, to initialize our model, we first have to pass it a mesh from which dimensions it builds its finite element representation, entirely based on the mesh on which the processes where defined. Then we differentiate our model into two functions, one that works on multiple inputs with multiprocessing and one only for single evaluations. **This differntation step is optional, only one of the two functions is needed**\n",
    "- **The functions as well as the aggregated Karhunen Loeve Results object are passed to a other newly defined class: KarhunenLoeveGeneralizedFunctionWrapper :\n",
    "    - As this class has access to the Karhunen-Loeve decomposition (which is as said the link between our differnt dimensions) and the model to analyse, this wrapper allows us to get a other view of the model, a view where the model is only dependent of a input vector of values following a centered reduced normal law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the model :\n",
    "_MODEL = MODEL.PureBeam(mesh)\n",
    "\n",
    "# initialization of the function wrapper : \n",
    "FUNC = klfs.KarhunenLoeveGeneralizedFunctionWrapper(\n",
    "                                AggregatedKarhunenLoeveResults = AggregatedKLRes,\n",
    "                                func        = _MODEL.singleEval, \n",
    "                                func_sample = _MODEL.batchEval,\n",
    "                                n_outputs   = 2) #We have to define the number of elements in the tuple the model returns !!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our model and input parameters we can begin to design our DOE (Design of experiment). We will generate mutiple DOEs, as we want to compare multiple methods together. \n",
    "- **As we know that ALL the components of the vector entering into our wrapped functions are following a centered resuced normal law we have different ways of generating our DOE.**\n",
    "    - First of all we need 3 types of DOEs :\n",
    "        - One for the krieging with 100 points : This one will be generated with the LHS sampling method. For this generation we do not need any class in particular. \n",
    "            - => For this sample we also need the response (or output) of the finite element model (FUNC) \n",
    "        - Two for the calculus of the sobol indices. These ones will be much bigger and will only follow a random sampling method. Only one of these samples will be evaluated on the finite element model. The other one will be evaluated on the krieging metamodel to compare the sobol indices in both cases. \n",
    "    - As we want to test the inluence of the different parameters having an influence we will prepaper multiple DOEs per type of DOE. :\n",
    "        - For the first type (the krieging model):\n",
    "            - one DOE with 50 points following the LHS sampling method    | SEED : 130875 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 100 points following the LHS sampling method   | SEED : 409484 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 200 points following the LHS sampling method   | SEED : 224409 => CALCULUS OF THE FEM MODEL RESPONSE\n",
    "\n",
    "        - For the second and third type (sobol on the fem model):\n",
    "            - one DOE with 1000 points following a random sampling method | SEED : 248214 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 2000 points following a random sampling method | SEED : 720442 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "            - one DOE with 4000 points following a random sampling method | SEED : 109242 => CALUCLUS OF THE FEM MODEL RESPONSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer\n",
    "\n",
    "\n",
    "# Little helper class for optimized lhs :\n",
    "@timer\n",
    "def optimizedLHS(distribution, size, seed):\n",
    "    ot.RandomGenerator.SetSeed(seed)\n",
    "    lhs = ot.LHSExperiment(distribution, size, True, True)\n",
    "    lhs_optimise = ot.SimulatedAnnealingLHS(lhs)\n",
    "    lhs_sample = lhs_optimise.generate()\n",
    "    return lhs_sample\n",
    "\n",
    "@timer\n",
    "def getSample(distribution, size, seed):\n",
    "    ot.RandomGenerator.SetSeed(seed)\n",
    "    sample = distribution.getSample(size)\n",
    "    sample.setDescription(distribution.getDescription())\n",
    "    return sample\n",
    "\n",
    "@timer \n",
    "def getSobolExperiment(size, seed):\n",
    "    ot.RandomGenerator.SetSeed(seed)    \n",
    "    experiment = klfs.KarhunenLoeveSobolIndicesExperiment(AggregatedKLRes, size)\n",
    "    sobolExp = experiment.generate()\n",
    "    return sobolExp, experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our design of experiment, we will need some data about our KL decomposition, namely the order of decomposition and a random normal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>ComposedDistribution(Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), Normal(mu = 0, sigma = 1), IndependentCopula(dimension = 18))</p>"
      ],
      "text/plain": [
       "class=ComposedDistribution name=ComposedDistribution dimension=18 copula=class=IndependentCopula name=IndependentCopula dimension=18 marginal[0]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[1]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[2]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[3]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[4]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[5]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[6]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[7]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[8]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[9]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[10]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[11]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[12]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[13]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[14]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[15]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[16]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1] marginal[17]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[0] sigma=class=Point name=Unnamed dimension=1 values=[1] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nModes = AggregatedKLRes.getSizeModes()  # the number of elements in the input vector of our KL wrapped model\n",
    "randNormVect = ot.ComposedDistribution([ot.Normal()] * nModes)  # \n",
    "randNormVect.setDescription(AggregatedKLRes._getModeDescription())\n",
    "randNormVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.2398 seconds\n",
      "Elapsed time: 0.9483 seconds\n",
      "Elapsed time: 3.8281 seconds\n",
      "First DOE type done\n",
      "\n",
      "Samples A and B of size 1000 and dimension 18\n",
      "Experiment of size 7000 and dimension 18\n",
      "Elapsed time: 0.2204 seconds\n",
      "Samples A and B of size 2000 and dimension 18\n",
      "Experiment of size 14000 and dimension 18\n",
      "Elapsed time: 0.4374 seconds\n",
      "Samples A and B of size 4000 and dimension 18\n",
      "Experiment of size 28000 and dimension 18\n",
      "Elapsed time: 1.9186 seconds\n",
      "Samples A and B of size 8000 and dimension 18\n",
      "Experiment of size 56000 and dimension 18\n",
      "Elapsed time: 3.6788 seconds\n",
      "Sobol Samples OK.\n",
      "Elapsed time: 3.5766 seconds\n"
     ]
    }
   ],
   "source": [
    "kg_doe50_130875   = optimizedLHS(randNormVect, 50, 130875)\n",
    "kg_doe100_409484  = optimizedLHS(randNormVect, 100, 409484)\n",
    "kg_doe200_224409  = optimizedLHS(randNormVect, 200, 224409)\n",
    "print('First DOE type done\\n')\n",
    "\n",
    "si_doe1000_248214, expe_doe1000 = getSobolExperiment(1000, 248214)\n",
    "si_doe2000_720442, expe_doe2000 = getSobolExperiment(2000, 720442)\n",
    "si_doe4000_109242, expe_doe4000 = getSobolExperiment(4000, 109242)\n",
    "si_doe8000_439038, expe_doe8000 = getSobolExperiment(8000, 439038)\n",
    "print('Sobol Samples OK.')\n",
    "\n",
    "valid_doe200_502849 = optimizedLHS(randNormVect, 200, 502849)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our design of expriments, we're going to evaluate the model on them, to get it's response. Then we're going to all save into csv files in  a folder, and use these as a basis for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOE_names      = ['kg_doe50_130875',      'kg_doe100_409484',      'kg_doe200_224409', \n",
    "                  'si_doe1000_248214',      'si_doe2000_720442',      'si_doe4000_109242',      'si_doe8000_439038',     'val_doe200_502849']\n",
    "DOE_resp_names = ['kg_doe50_130875_resp', 'kg_doe100_409484_resp', 'kg_doe200_224409_resp', \n",
    "                  'si_doe1000_248214_resp', 'si_doe2000_720442_resp', 'si_doe4000_109242_resp', 'si_doe8000_439038_resp','val_doe200_502849_resp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_DOEs = [kg_doe50_130875,kg_doe100_409484,kg_doe200_224409,si_doe1000_248214,si_doe2000_720442,si_doe4000_109242, si_doe8000_439038, valid_doe200_502849]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.5s finished\n",
      "/home/simady/anaconda/envs/pythontools/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (50, 103)  should be [N,10X] something\n",
      "deflection std deviation  5.832357303786302\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (50, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (50,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1930s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (100, 103)  should be [N,10X] something\n",
      "deflection std deviation  6.115552702644656\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (100, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (100,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (200, 103)  should be [N,10X] something\n",
      "deflection std deviation  6.827724263273351\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (200, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (200,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1941s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 652 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 938 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1132 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1498 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1740 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1826 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1912 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2092 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2186 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2378 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2476 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2578 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2680 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2786 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3002 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3112 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3226 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3340 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3458 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3576 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3698 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3820 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4072 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4202 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4332 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4466 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4738 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4876 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5018 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5306 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5452 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5602 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5752 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5906 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6060 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6218 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6376 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6700 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6866 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7000 out of 7000 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (7000, 103)  should be [N,10X] something\n",
      "deflection std deviation  nan\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (7000, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (7000,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3953 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4224 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4317 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4410 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4505 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4697 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5093 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5297 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5505 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5610 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5717 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5933 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6153 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6264 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6377 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6605 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6720 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6954 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7073 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7313 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7434 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7557 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7680 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7805 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8057 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8184 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8313 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8573 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8704 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8837 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8970 tasks      | elapsed:  8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9240 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9377 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9514 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9653 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9933 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10074 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10217 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10505 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10650 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10797 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10944 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11093 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11393 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11544 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11697 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11850 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12005 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12160 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12317 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12474 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12633 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12953 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 13277 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 13440 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 13605 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13770 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 13937 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14000 out of 14000 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (14000, 103)  should be [N,10X] something\n",
      "deflection std deviation  6.144452160356576\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (14000, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (14000,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1957s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 652 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 938 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1132 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1498 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1740 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1826 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1912 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2092 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2186 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2378 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2476 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2578 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2680 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2786 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2892 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3002 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3112 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3226 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3340 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3458 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3576 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3698 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3820 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3946 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4072 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4202 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4332 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4466 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4738 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4876 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5018 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5160 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5306 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5452 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5602 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5752 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5906 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6060 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6218 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6376 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6538 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6700 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6866 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7032 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7202 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7372 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7546 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7720 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7898 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8076 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8258 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8440 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8626 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8812 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9002 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9192 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9386 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9580 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9778 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9976 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10178 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10380 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10586 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10792 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11002 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11212 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11426 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11640 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11858 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12076 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12298 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12520 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12746 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12972 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13202 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13432 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 13666 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 13900 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14138 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14376 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14618 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14860 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 15106 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15352 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 15602 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 15852 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16106 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 16360 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16618 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16876 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 17138 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 17400 tasks      | elapsed: 15.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 17666 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 17932 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18202 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 18472 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18746 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 19020 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19298 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 19576 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19858 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 20140 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 20426 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 20712 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 21002 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 21292 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 21586 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 21880 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22178 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22476 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 22778 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 23080 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 23386 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 23692 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 24002 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 24312 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 24626 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 24940 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25258 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 25576 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 25898 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26220 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26546 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26872 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 27202 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 27532 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 27866 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 28000 out of 28000 | elapsed: 25.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape deflection:  (28000, 103)  should be [N,10X] something\n",
      "deflection std deviation  nan\n",
      "Using the batch evaluation function. Assumes that the outputs are in the \n",
      "same order than for the single evaluation function. This one should only \n",
      "return ProcessSamples, Samples, Lists or numpy arrays.\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (28000, 102) and dtype is <class 'numpy.float64'>\n",
      "Element 0 of the output tuple returns process samples of dimension 1\n",
      "Element is iterable, assumes that first dimension is size of sample\n",
      "Shape is (28000,) and dtype is <class 'numpy.float64'>\n",
      "Element 1 of the output tuple returns samples of dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:   23.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-82df238d0190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_DOEs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDOE_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFUNC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mvonMises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmaxDefl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spsa/MethodValidationScriptsStandalone/KarhunenLoeveFieldSensitivity/_karhunenLoeveGeneralizedFunctionWrapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spsa/MethodValidationScriptsStandalone/KarhunenLoeveFieldSensitivity/_karhunenLoeveGeneralizedFunctionWrapper.py\u001b[0m in \u001b[0;36m_exec_sample\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0minputProcessSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__AKLR__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliftAsProcessSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputProcessSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matLeastList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_exec_sample_ot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spsa/MethodValidationScriptsStandalone/PureBeamExample.py\u001b[0m in \u001b[0;36mbatchEval\u001b[0;34m(self, argList)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatchEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvertSinglInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartialBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartialArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spsa/MethodValidationScriptsStandalone/PureBeamExample.py\u001b[0m in \u001b[0;36mbatchEval\u001b[0;34m(self, random_young_modulus, random_diameter, random_density, random_forcePos, random_forceNorm)\u001b[0m\n\u001b[1;32m     30\u001b[0m                   random_forceNorm):\n\u001b[1;32m     31\u001b[0m         \u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_young_modulus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_diameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_density\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_forcePos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_forceNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlElem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         result_list = Parallel(n_jobs=-1, verbose=10)(\n\u001b[0m\u001b[1;32m     33\u001b[0m                         delayed(_BeamBase.experience)(\n\u001b[1;32m     34\u001b[0m                             var1[i], var2[i], var3[i], var4[i], var5[i], var6, var7) for i in range(len(var5)))\n",
      "\u001b[0;32m~/anaconda/envs/stochastic_field_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/stochastic_field_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/stochastic_field_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/stochastic_field_env/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/stochastic_field_env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder = './DOE_RESP'\n",
    "for i, doe in enumerate(l_DOEs):\n",
    "    if os.path.isfile(os.path.join(folder,DOE_names[i]+'.csv')):\n",
    "        resp = FUNC(doe)\n",
    "        vonMises = ot.Sample(np.array(np.stack([np.squeeze(np.asarray(resp[0][i])) for i in range(len(resp[0]))]))) \n",
    "        maxDefl = resp[1]\n",
    "        doe.exportToCSVFile(os.path.join(folder,DOE_names[i]+'.csv'), ';')\n",
    "        vonMises.exportToCSVFile(os.path.join(folder,DOE_resp_names[i]+'_VM'+'.csv'), ';')\n",
    "        maxDefl.exportToCSVFile(os.path.join(folder,DOE_resp_names[i]+'_MD'+'.csv'), ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
