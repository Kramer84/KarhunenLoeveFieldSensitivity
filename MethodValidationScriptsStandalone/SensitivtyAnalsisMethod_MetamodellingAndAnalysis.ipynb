{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have our designs of experiment, we can begin to create our metamodels. In our case, we will create 3 metamodels, each created from a different (in size and elements) design of experiment. We will then assess the precision of our metamodel in regard to the functions ouput, and further we will look at the sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openturns as ot\n",
    "import pythontools as pt\n",
    "from collections import Sequence, Iterable\n",
    "import KarhunenLoeveFieldSensitivity as klfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DOE_RESP2/kg_doe50_130875.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6f37c9e7a3e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lets' first load our 3 designs of experiment for the kriging models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# input designs :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoe50_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DOE_RESP2/kg_doe50_130875.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdoe100_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DOE_RESP2/kg_doe100_409484.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoe200_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DOE_RESP2/kg_doe200_224409.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kramer84/anaconda3/envs/stochastic_field_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DOE_RESP2/kg_doe50_130875.csv'"
     ]
    }
   ],
   "source": [
    "# Lets' first load our 3 designs of experiment for the kriging models. \n",
    "# input designs : \n",
    "doe50_in = pd.read_csv('DOE_RESP2/kg_doe50_130875.csv', sep=';')\n",
    "doe100_in = pd.read_csv('DOE_RESP2/kg_doe100_409484.csv', sep=';')\n",
    "doe200_in = pd.read_csv('DOE_RESP2/kg_doe200_224409.csv', sep=';')\n",
    "# model outputs :\n",
    "doe50_out_MD = pd.read_csv('DOE_RESP2/kg_doe50_130875_resp_MD.csv', sep=';', header=None)\n",
    "doe50_VM = pd.read_csv('DOE_RESP2/kg_doe50_130875_resp_VM.csv', sep=';', header=None)\n",
    "doe100_out_MD = pd.read_csv('DOE_RESP2/kg_doe100_409484_resp_MD.csv', header=None)\n",
    "doe100_VM = pd.read_csv('DOE_RESP2/kg_doe100_409484_resp_VM.csv', sep=';', header=None)\n",
    "doe200_out_MD = pd.read_csv('DOE_RESP2/kg_doe200_224409_resp_MD.csv', sep=';', header=None)\n",
    "doe200_VM = pd.read_csv('DOE_RESP2/kg_doe200_224409_resp_VM.csv', sep=';', header=None)\n",
    "# validation models : \n",
    "doe_vali_200_in = pd.read_csv('DOE_RESP2/val_doe200_502849.csv', sep=';')\n",
    "doe_vali_200_out_MD = pd.read_csv('DOE_RESP2/val_doe200_502849_resp_MD.csv', sep=';',header=None)\n",
    "doe_vali_200_out_VM = pd.read_csv('DOE_RESP2/val_doe200_502849_resp_VM.csv', sep=';',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_same(items=None):\n",
    "    #Checks if all items of a list are the same\n",
    "    return all(x == items[0] for x in items)\n",
    "\n",
    "def isValidSobolIndicesExperiment(sample_like, size, second_order = False):\n",
    "    try :\n",
    "        sample = np.asarray(sample_like)\n",
    "    except :\n",
    "        print('Could not convert sample to numpy array')\n",
    "        raise TypeError\n",
    "    N = sample.shape[0]\n",
    "    print('N is', N)\n",
    "    dim = sample.shape[1]\n",
    "    Y_A = sample[:size]\n",
    "    Y_B = sample[size:2*size]\n",
    "    N_indice = int(N/size - 2)\n",
    "    assert N%size==0,\"wrong sample size\"\n",
    "    print('Simplified view of the sobol indices experiments structure')\n",
    "    print('There are {} dimensions and {} sobol indices to calculate'.format(dim, N_indice))\n",
    "    assert np.where(Y_A==Y_B,True,False).any() == False #Here we check that there is no similarity at all  between A and B \n",
    "    tot_lines = list()\n",
    "    try : \n",
    "        for i in range(N_indice+2):\n",
    "            Y_E = sample[i*size:(i+1)*size]\n",
    "            tot_cols = [True]*dim\n",
    "            col_where_A = list(set(np.argwhere(Y_A==Y_E)[:,1]))\n",
    "            line_where_A = list(set(np.argwhere(Y_A==Y_E)[:,0]))\n",
    "            if len(line_where_A)==size : OK = True\n",
    "            for co in col_where_A :\n",
    "                tot_cols[co] = False\n",
    "            if OK : \n",
    "                if len(col_where_A)==dim and all(tot_cols):\n",
    "                    sl = ['A_'+str(j) for j in range(dim)]\n",
    "                elif len(col_where_A)==0 and all_same(tot_cols):\n",
    "                    sl = ['B_'+str(j) for j in range(dim)]\n",
    "                else :\n",
    "                    sl = ['B_'+str(j) for j in range(dim)]\n",
    "                    for k in range(len(col_where_A)):\n",
    "                        sl[col_where_A[k]] = 'A_'+str(col_where_A[k])\n",
    "                l = \"  ,    \".join(sl)\n",
    "                l = '    '+l\n",
    "            if not OK :\n",
    "                print('Error')\n",
    "                return False\n",
    "            tot_lines.append(l)\n",
    "        repres = ' \\n\\n'.join(tot_lines)\n",
    "        repres = '\\n'+repres\n",
    "        print(repres) \n",
    "        return True\n",
    "    except :\n",
    "        return False\n",
    "\n",
    "def ereaseNanFromSample(sample_in, sample_out, N , secondOrder = False):\n",
    "    sampOut = np.array(sample_out,copy=True, subok=False)\n",
    "    if secondOrder == False : \n",
    "        n_vars = int(sampOut.shape[0]/N) - 2 \n",
    "        print('n vars is', n_vars)\n",
    "        N_max = int(N*(n_vars + 2))\n",
    "        N_var = N_max/N\n",
    "    else : \n",
    "        n_vars = int(sampOut.shape[0]/(N*2)) - 1\n",
    "        print('n vars is', n_vars)\n",
    "        N_max = int(N*(2*n_vars + 2))\n",
    "        N_var = N_max/N\n",
    "    \n",
    "    print('N_max is', N_max)\n",
    "    argNan = np.argwhere(np.isnan(sampOut))[:,0].tolist()\n",
    "    print('args where nan : ',argNan)\n",
    "    toErease = set()\n",
    "    for arg in argNan:\n",
    "        whereToErease = list(range(arg%N, N_max, N))\n",
    "        [toErease.add(elem) for elem in whereToErease]\n",
    "    whereToErease = list(toErease)\n",
    "    print('Where we are erasing:', whereToErease)\n",
    "    N -= int(len(whereToErease)/N_var)\n",
    "    for idx in sorted(whereToErease)[::-1]:\n",
    "        sample_in.erase(idx)\n",
    "        sample_out.erase(idx) \n",
    "    print('N is now: ',N)\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIGING SAMPLE\n",
    "    # INPUTS\n",
    "sample_doe50_in = ot.Sample(doe50_in.values)\n",
    "sample_doe50_in.setDescription(doe50_in.columns)\n",
    "sample_doe100_in = ot.Sample(doe100_in.values)\n",
    "sample_doe100_in.setDescription(doe100_in.columns)\n",
    "sample_doe200_in = ot.Sample(doe200_in.values)\n",
    "sample_doe200_in.setDescription(doe200_in.columns)\n",
    "    # OUTPUTS\n",
    "sample_doe50_out_MD = ot.Sample(doe50_out_MD.values)\n",
    "sample_doe50_out_MD.setDescription(ot.Description.BuildDefault(len(doe50_out_MD.columns), 'MD_'))\n",
    "sample_doe50_VM = ot.Sample(doe50_VM.values)\n",
    "sample_doe50_VM.setDescription(ot.Description.BuildDefault(len(doe50_VM.columns), 'VM_'))\n",
    "sample_doe100_out_MD = ot.Sample(doe100_out_MD.values)\n",
    "sample_doe100_out_MD.setDescription(ot.Description.BuildDefault(len(doe100_out_MD.columns), 'MD_'))\n",
    "sample_doe100_VM = ot.Sample(doe100_VM.values)\n",
    "sample_doe100_VM.setDescription(ot.Description.BuildDefault(len(doe100_VM.columns), 'VM_'))\n",
    "sample_doe200_out_MD = ot.Sample(doe200_out_MD.values)\n",
    "sample_doe200_out_MD.setDescription(ot.Description.BuildDefault(len(doe200_out_MD.columns), 'MD_'))\n",
    "sample_doe200_VM = ot.Sample(doe200_VM.values)\n",
    "sample_doe200_VM.setDescription(ot.Description.BuildDefault(len(doe200_VM.columns), 'VM_'))\n",
    "# VALIDATION SAMPLE\n",
    "validation_sample_doe200_in = ot.Sample(doe_vali_200_in.values)\n",
    "validation_sample_doe200_in.setDescription(doe_vali_200_in.columns)\n",
    "validation_sample_doe200_out_MD = ot.Sample(doe_vali_200_out_MD.values)\n",
    "validation_sample_doe200_out_MD.setDescription(ot.Description.BuildDefault(len(doe_vali_200_out_MD.columns), 'MD_'))\n",
    "validation_sample_doe200_out_VM = ot.Sample(doe_vali_200_out_VM.values)\n",
    "validation_sample_doe200_out_VM.setDescription(ot.Description.BuildDefault(len(doe_vali_200_out_VM.columns), 'VM_'))\n",
    "sample_doe50_in.getDescription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's define a metamodeling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class metamodeling_kriging : \n",
    "    def __init__(self, inSample, outSample, **kwargs):\n",
    "        self.input_sample = inSample\n",
    "        self.output_sample = outSample\n",
    "        self.__default_kriging__ = None\n",
    "        self.__kriging_theta__ = None\n",
    "        self.__kriging_results__ = None\n",
    "        self.__kriging_metamodel__ = None\n",
    "        self.__size_multistart__ = kwargs['size_multistart'] if 'size_multistart' in kwargs else 5\n",
    "        self.__lb__ = kwargs['lower_bound'] if 'lower_bound' in kwargs else None\n",
    "        self.__ub__ = kwargs['upper_bound'] if 'upper_bound' in kwargs else None\n",
    "        self.__optim_type__ = kwargs['optim_type'] if 'optim_type' in kwargs else 'best_start'\n",
    "        self.validation_results = __validation_results__() \n",
    "        \n",
    "    def _build_default(self):\n",
    "        self.__default_kriging__ = pt.build_default_kriging_algo(\n",
    "                                    input_sample  = self.input_sample,\n",
    "                                    output_sample = self.output_sample, \n",
    "                                    basis         = None,\n",
    "                                    covariance_model = None,\n",
    "                                    noise         = None)\n",
    "        \n",
    "    def _estimate_theta(self):\n",
    "        self.__kriging_theta__ = pt.estimate_kriging_theta(\n",
    "                            algo_kriging = self.__default_kriging__,\n",
    "                            lower_bound = self.__lb__,\n",
    "                            upper_bound = self.__ub__,\n",
    "                            size        = self.__size_multistart__,\n",
    "                            optim_type  = self.__optim_type__)\n",
    "    \n",
    "    def _get_results_metamodel(self):\n",
    "        if isinstance(self.__kriging_theta__,(Sequence,Iterable, list)):\n",
    "            self.__kriging_results__ = [_kt.getResult() for _kt in self.__kriging_theta__]\n",
    "            self.__kriging_metamodel__ = [_km.getMetaModel() for _km in self.__kriging_results__]\n",
    "        else :\n",
    "            self.__kriging_results__ = self.__kriging_theta__.getResult()\n",
    "            self.__kriging_metamodel__ = self.__kriging_results__.getMetaModel()\n",
    "                \n",
    "    def run(self):\n",
    "        self._build_default()\n",
    "        self._estimate_theta()\n",
    "        self._get_results_metamodel()\n",
    "        print('Done !')\n",
    "        \n",
    "    def getKrigingResult(self):\n",
    "        return self.__kriging_results__\n",
    "        \n",
    "    def getKrigingMetaModel(self):\n",
    "        return self.__kriging_metamodel__\n",
    "    \n",
    "    def _check_clean_nans(self, sampleIn, sampleOut):\n",
    "        whereNan = list(set(np.argwhere(np.isnan(sampleOut))[:,0]))\n",
    "        print('NaN values found at index:',whereNan)\n",
    "        [(sampleOut.erase(int(val)), sampleIn.erase(int(val))) for val in whereNan]\n",
    "        \n",
    "    def getMetaModelValidation(self, sample_in_validation, sample_out_validation):\n",
    "        assert self.__kriging_metamodel__ is not None, \"Please first run calculus\"\n",
    "        assert len(sample_in_validation) == len(sample_out_validation)\n",
    "        self._check_clean_nans(sample_in_validation, sample_out_validation)\n",
    "        self.validation_results.clear()\n",
    "        if isinstance(self.__kriging_metamodel__,(Sequence,Iterable, list)):\n",
    "            for i, model in enumerate(self.__kriging_metamodel__):\n",
    "                validation = ot.MetaModelValidation(sample_in_validation, \n",
    "                                                    sample_out_validation[:,i],\n",
    "                                                    self.__kriging_metamodel__[i])\n",
    "                R2 = validation.computePredictivityFactor()\n",
    "                residual = validation.getResidualSample()\n",
    "                graph = validation.drawValidation()\n",
    "                self.validation_results.addGraph(graph)\n",
    "                self.validation_results.addR2(R2)\n",
    "                self.validation_results.addResidual(residual)\n",
    "        else : \n",
    "            validation = ot.MetaModelValidation(sample_in_validation, \n",
    "                                                sample_out_validation[:,0],\n",
    "                                                self.__kriging_metamodel__)\n",
    "            R2 = validation.computePredictivityFactor()\n",
    "            residual = validation.getResidualSample()\n",
    "            graph = validation.drawValidation()\n",
    "            self.validation_results.addGraph(graph)\n",
    "            self.validation_results.addR2(R2)\n",
    "            self.validation_results.addResidual(residual)\n",
    "                \n",
    "class __validation_results__(object) :\n",
    "    def __init__(self): \n",
    "        self.__R2__ = []\n",
    "        self.__residuals__ = []\n",
    "        self.__graphs__ = []\n",
    "\n",
    "    def clear(self):\n",
    "        self.__R2__.clear()\n",
    "        self.__residuals__.clear()\n",
    "        self.__graphs__.clear()\n",
    "        \n",
    "    def addGraph(self, graph):\n",
    "        self.__graphs__.append(graph)\n",
    "\n",
    "    def addR2(self, R2):\n",
    "        self.__R2__.append(R2)\n",
    "\n",
    "    def addResidual(self, residual):\n",
    "        self.__residuals__.append(residual)\n",
    "\n",
    "    def getGraphs(self):\n",
    "        for graph in self.__graphs__ :\n",
    "            ot.Show(graph)\n",
    "\n",
    "    def getResiduals(self):\n",
    "        theGraph = ot.Graph('Residuals','varying dimension','residual',True,'')\n",
    "        theCurve = ot.Curve(list(range(len(self.__residuals__))),\n",
    "                            self.__residuals__, 'residuals')\n",
    "        theGraph.add(theCurve)\n",
    "        ot.Show(theGraph)\n",
    "\n",
    "    def getR2s(self):\n",
    "        theGraph = ot.Graph('R2','varying dimension','residual',True,'')\n",
    "        theCurve = ot.Curve(list(range(len(self.__R2__))),\n",
    "                            self.__R2__, 'R2')\n",
    "        theGraph.add(theCurve)\n",
    "        ot.Show(theGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First metamodel, DOE : LHS 50  ==> Max Deflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_50_MD = metamodeling_kriging(sample_doe50_in, sample_doe50_out_MD,optim_type='multi_start', size_multistart = 10)\n",
    "kriging_doe_50_MD.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For validation, we are going to use one of the samples intended for the sobol indices calculus. by the way, we are only going to use the 2/7 th of the samples (as we have samples A, B, and then 5 combinations of those.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_sample_doe2000_in | validation_sample_doe2000_out_MD | validation_sample_doe2000_out_VM\n",
    "kriging_doe_50_MD.getMetaModelValidation(validation_sample_doe200_in, validation_sample_doe200_out_MD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_50_MD.validation_results.getGraphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As we see, the results here are not so horrible ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second metamodel, DOE : LHS 100  ==> Max Deflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_100_MD = metamodeling_kriging(sample_doe100_in, \n",
    "                                        sample_doe100_out_MD, \n",
    "                                        optim_type='best_start',\n",
    "                                        size_multistart = 100,\n",
    "                                        lower_bound = None,\n",
    "                                        upper_bound = None)\n",
    "kriging_doe_100_MD.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_100_MD.getMetaModelValidation(validation_sample_doe200_in, validation_sample_doe200_out_MD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kriging_doe_100_MD.validation_results.getGraphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third metamodel, DOE : LHS 200  ==> Max Deflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD = metamodeling_kriging(sample_doe200_in, \n",
    "                                        sample_doe200_out_MD, \n",
    "                                        optim_type='best_start',\n",
    "                                        size_multistart = 100,\n",
    "\n",
    "                                        lower_bound = None,\n",
    "                                        upper_bound = None)\n",
    "kriging_doe_200_MD.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD.getMetaModelValidation(validation_sample_doe200_in, validation_sample_doe200_out_MD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD.validation_results.getGraphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the sensitivity analysis parts. Let's do the sensitivty analysis of the 3 metamodels.\n",
    "\n",
    "We will first have to load the sample intended to the calculus of the sobol indices, in hope we will find no nan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_2000_in = pd.read_csv('DOE_RESP2/si_doe2000_720442.csv', sep=';')\n",
    "si_2000_out_MD = pd.read_csv('DOE_RESP2/si_doe2000_720442_resp_MD.csv', sep=';',header=None)\n",
    "si_2000_out_VM = pd.read_csv('DOE_RESP2/si_doe2000_720442_resp_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_2000_in = ot.Sample(si_2000_in.values)\n",
    "sample_si_2000_in.setDescription(si_2000_in.columns)\n",
    "\n",
    "sample_si_2000_out_MD = ot.Sample(si_2000_out_MD.values)\n",
    "sample_si_2000_out_MD.setDescription(ot.Description.BuildDefault(len(si_2000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_2000_out_VM = ot.Sample(si_2000_out_VM.values)\n",
    "sample_si_2000_out_VM.setDescription(ot.Description.BuildDefault(len(si_2000_out_VM.columns), 'VM_'))\n",
    "\n",
    "si_1000_in = pd.read_csv('DOE_RESP2/si_doe1000_248214.csv', sep=';')\n",
    "si_1000_out_MD = pd.read_csv('DOE_RESP2/si_doe1000_248214_resp_MD.csv', sep=';',header=None)\n",
    "si_1000_out_VM = pd.read_csv('DOE_RESP2/si_doe1000_248214_resp_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_1000_in = ot.Sample(si_1000_in.values)\n",
    "sample_si_1000_in.setDescription(si_1000_in.columns)\n",
    "\n",
    "sample_si_1000_out_MD = ot.Sample(si_1000_out_MD.values)\n",
    "sample_si_1000_out_MD.setDescription(ot.Description.BuildDefault(len(si_1000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_1000_out_VM = ot.Sample(si_1000_out_VM.values)\n",
    "sample_si_1000_out_VM.setDescription(ot.Description.BuildDefault(len(si_1000_out_VM.columns), 'VM_'))\n",
    "sample_si_2000_in.getSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_2000 = ereaseNanFromSample(sample_si_2000_in, sample_si_2000_out_MD, 2000, False)\n",
    "sample_si_2000_in.getSize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_si_2000_in[7777,5]=256\n",
    "isValidSobolIndicesExperiment(sample_si_2000_in,N_2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD.getMetaModelValidation(sample_si_2000_in, sample_si_2000_out_MD)\n",
    "kriging_doe_200_MD.validation_results.getGraphs()\n",
    "#Astuce / plan d'experience en augmentant coeff de variation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1000 = ereaseNanFromSample(sample_si_1000_in, sample_si_1000_out_MD, 1000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD.getMetaModelValidation(sample_si_1000_in, sample_si_1000_out_MD)\n",
    "kriging_doe_200_MD.validation_results.getGraphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_1000 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_REAL_MODEL_1000.setDesign(sample_si_1000_in, sample_si_1000_out_MD, N_1000)\n",
    "sensitivityAnalysis_REAL_MODEL_1000.setEstimator(ot.SaltelliSensitivityAlgorithm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spsa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = spsa.SobolIndicesStochasticProcessAlgorithm(np.array(sample_si_1000_out_MD),N_1000)\n",
    "analysis.getFirstOrderIndices()   ##### THE SOBOL INDICES CALCULUS IS RIGHT!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_1000.getFirstOrderIndices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_1000.__results__[0].getFirstOrderIndicesDistribution().getMarginal(0).getStandardDeviation()\n",
    "res = sensitivityAnalysis_REAL_MODEL_1000.__results__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_1000.getFirstOrderIndicesInterval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_1000.getTotalOrderIndices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL_2000 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_REAL_MODEL_2000.setDesign(sample_si_2000_in, sample_si_2000_out_MD, N_2000)\n",
    "sensitivityAnalysis_REAL_MODEL_2000.setEstimator(ot.SaltelliSensitivityAlgorithm())\n",
    "sensitivityAnalysis_REAL_MODEL_2000.getFirstOrderIndices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_8000_in = pd.read_csv('DOE_RESP2/si_doe8000_439038.csv', sep=';')\n",
    "si_8000_out_MD = pd.read_csv('DOE_RESP2/si_doe8000_439038_resp_MD.csv', sep=';',header=None)\n",
    "si_8000_out_VM = pd.read_csv('DOE_RESP2/si_doe8000_439038_resp_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_8000_in = ot.Sample(si_8000_in.values)\n",
    "sample_si_8000_in.setDescription(si_8000_in.columns)\n",
    "\n",
    "sample_si_8000_out_MD = ot.Sample(si_8000_out_MD.values)\n",
    "sample_si_8000_out_MD.setDescription(ot.Description.BuildDefault(len(si_8000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_8000_out_VM = ot.Sample(si_8000_out_VM.values)\n",
    "sample_si_8000_out_VM.setDescription(ot.Description.BuildDefault(len(si_8000_out_VM.columns), 'VM_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whereNan = np.argwhere(np.isnan(sample_si_8000_out_MD))[:,0].tolist()\n",
    "N = 8000\n",
    "N_MAX = 8000*7\n",
    "toDelete = set()\n",
    "print('Where nan:', whereNan)\n",
    "for idx in whereNan:\n",
    "    toErease = list(range(idx%8000,N_MAX,N))\n",
    "    [toDelete.add(elem) for elem in toErease]\n",
    "print('toErease is', toDelete)\n",
    "toDelete = list(toDelete)\n",
    "N-=int(len(toDelete)/7)\n",
    "for idx in sorted(toDelete)[::-1] :\n",
    "    sample_si_8000_in.erase(idx)\n",
    "    sample_si_8000_out_MD.erase(idx)\n",
    "print('N=',N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_REAL_MODEL2.setDesign(sample_si_8000_in, sample_si_8000_out_MD, N)\n",
    "sensitivityAnalysis_REAL_MODEL2.setEstimator(ot.SaltelliSensitivityAlgorithm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2.getTotalOrderIndices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in this new sensitivity analysis are totally different from our first one, we have to check if either this analysis or the other is broken. For this we are first going to calculate the first and second order indices to see if something changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_sec_2000_in = pd.read_csv('DOE_RESP/si_sec_doe2000_8291001288.csv', sep=';')\n",
    "si_sec_2000_out_MD = pd.read_csv('DOE_RESP/si_sec_doe2000_8291001288_resp_MD.csv', sep=';',header=None)\n",
    "si_sec_2000_out_VM = pd.read_csv('DOE_RESP/si_sec_doe2000_8291001288_resp_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_sec_2000_in = ot.Sample(si_sec_2000_in.values)\n",
    "sample_si_sec_2000_in.setDescription(si_sec_2000_in.columns)\n",
    "\n",
    "sample_si_sec_2000_out_MD = ot.Sample(si_sec_2000_out_MD.values)\n",
    "sample_si_sec_2000_out_MD.setDescription(ot.Description.BuildDefault(len(si_sec_2000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_sec_2000_out_VM = ot.Sample(si_sec_2000_out_VM.values)\n",
    "sample_si_sec_2000_out_VM.setDescription(ot.Description.BuildDefault(len(si_sec_2000_out_VM.columns), 'VM_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sec_2000 = ereaseNanFromSample(sample_si_sec_2000_in , sample_si_sec_2000_out_MD, 2000, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isValidSobolIndicesExperiment(sample_si_sec_2000_in, N_sec_2000,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_REAL_MODEL2.setDesign(sample_si_sec_2000_in, sample_si_sec_2000_out_MD, N_sec_2000)\n",
    "sensitivityAnalysis_REAL_MODEL2.setEstimator(ot.SaltelliSensitivityAlgorithm())\n",
    "sensitivityAnalysis_REAL_MODEL2.setComputeSecondOrder(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2.inputDescription\n",
    "sensitivityAnalysis_REAL_MODEL2.__nSobolIndices__\n",
    "sensitivityAnalysis_REAL_MODEL2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivityAnalysis_REAL_MODEL2.getSecondOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_10000_in = pd.read_csv('./inp_10000.csv', sep=';')\n",
    "si_10000_out_MD = pd.read_csv('./out_10000_MD.csv', sep=';')\n",
    "si_10000_out_VM = pd.read_csv('./out_10000_VM.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_10000_in = pd.read_csv('./inp_10000.csv', sep=';')\n",
    "si_10000_out_MD = pd.read_csv('./out_10000_MD.csv', sep=';',header=None)\n",
    "si_10000_out_VM = pd.read_csv('./out_10000_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_10000_in = ot.Sample(si_10000_in.values)\n",
    "sample_si_10000_in.setDescription(si_10000_in.columns)\n",
    "\n",
    "sample_si_10000_out_MD = ot.Sample(si_10000_out_MD.values)\n",
    "sample_si_10000_out_MD.setDescription(ot.Description.BuildDefault(len(si_10000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_10000_out_VM = ot.Sample(si_10000_out_VM.values)\n",
    "sample_si_10000_out_VM.setDescription(ot.Description.BuildDefault(len(si_10000_out_VM.columns), 'VM_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_10000.setDesign(sample_si_10000_in, sample_si_10000_out_MD, 10000)\n",
    "sensitivityAnalysis_10000.setEstimator(ot.SaltelliSensitivityAlgorithm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000.getFirstOrderIndicesInterval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000_2 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_10000_2.setDesign(sample_si_10000_in, sample_si_10000_out_MD, 10000)\n",
    "sensitivityAnalysis_10000_2.setEstimator(ot.MartinezSensitivityAlgorithm())\n",
    "sensitivityAnalysis_10000_2.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000_2.getFirstOrderIndicesInterval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2 = spsa.SobolIndicesStochasticProcessAlgorithm(np.array(sample_si_10000_out_MD),10000)\n",
    "analysis2.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2.getFirstOrderIndicesInterval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_50000_in = pd.read_csv('./inp_50000.csv', sep=';')\n",
    "si_50000_out_MD = pd.read_csv('./out_50000_MD.csv', sep=';',header=None)\n",
    "si_50000_out_VM = pd.read_csv('./out_50000_VM.csv', sep=';',header=None)\n",
    "#Samples\n",
    "sample_si_50000_in = ot.Sample(si_50000_in.values)\n",
    "sample_si_50000_in.setDescription(si_50000_in.columns)\n",
    "\n",
    "sample_si_50000_out_MD = ot.Sample(si_50000_out_MD.values)\n",
    "sample_si_50000_out_MD.setDescription(ot.Description.BuildDefault(len(si_50000_out_MD.columns), 'MD_'))\n",
    "\n",
    "sample_si_50000_out_VM = ot.Sample(si_50000_out_VM.values)\n",
    "sample_si_50000_out_VM.setDescription(ot.Description.BuildDefault(len(si_50000_out_VM.columns), 'VM_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_50000.setDesign(sample_si_50000_in, sample_si_50000_out_MD, 50000)\n",
    "sensitivityAnalysis_50000.setEstimator(ot.SaltelliSensitivityAlgorithm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000.getFirstOrderIndicesInterval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_50000.setDesign(sample_si_50000_in, sample_si_50000_out_MD, 50000)\n",
    "sensitivityAnalysis_50000.setEstimator(ot.MartinezSensitivityAlgorithm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_50000.getFirstOrderIndicesInterval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis50000 = spsa.SobolIndicesStochasticProcessAlgorithm(np.array(sample_si_50000_out_MD),50000)\n",
    "analysis50000.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis50000.getFirstOrderIndicesInterval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis of the metamodels \n",
    "\n",
    "Here we are going to do the same sensitivity analysis, but based on the metamodel of the bending beam model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriging_doe_200_MD.__kriging_metamodel__.getInputDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_50000 = pd.read_csv('./inp_50000.csv', sep=';')\n",
    "sample_inp_50000 = ot.Sample(inp_50000.values)\n",
    "sample_inp_50000.setDescription(inp_50000.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_meatamodel50000 = kriging_doe_200_MD.__kriging_metamodel__(sample_inp_50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inp_50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityAnalysis_10000_2 = klfs.SobolKarhunenLoeveFieldSensitivityAlgorithm()\n",
    "sensitivityAnalysis_10000_2.setDesign(sample_inp_50000, resp_meatamodel50000, 10000)\n",
    "sensitivityAnalysis_10000_2.setEstimator(ot.MartinezSensitivityAlgorithm())\n",
    "sensitivityAnalysis_10000_2.getFirstOrderIndices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaire experience avec les mêmes samples pour le métamodele et le vrai modèle. \n",
    "(Plus vérification avec assert_equal() )\n",
    "Nouveau Notebook plus concis + calculs R2 + graphes + introduire coef var dans params entrée + simplifier fonctions et mettre dans fichier à part. \n",
    "Cas tests :\n",
    "  - D'abord kriegage (modifs taille DOE LHS) + écarts vrai modèle /metamodele\n",
    "  - Sur paramètres entrée (variance, amplitude, scale... ) \n",
    "  - Sauvegarder chaque resultat\n",
    "  - DF Pandas: ordonnées (indices de sobol) | abscisses : (Taille DOE due kriegage + taille plan d'experience) \n",
    "  - Tests chaos polynomial + visualisation + (analyser IS des sigma et des params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
